{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWRAj0orQgw5El0sLdT1UF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codebuzer/Bioactivity-Prediction-App/blob/main/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSmcg3zNoK58",
        "outputId": "8a702a0f-c52c-4754-a8c8-58fdc52088dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QJcsXfooMym",
        "outputId": "848524ca-5579-4eb3-fcbb-6b65b9447fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0+zzzcolab20220506162203)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import Sequential"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "jLCkUbRHojwU",
        "outputId": "007b7dea-acc6-4d72-a75a-c607d8c24c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7aab57606ad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Sequential' from 'tensorflow' (/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6dZb8oBBopQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"toy_data_model.csv\")"
      ],
      "metadata": {
        "id": "yu0d1QPatjwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "8TNbOb6it24X",
        "outputId": "900f67ca-fb2f-4471-d240-af7785582e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  ID  AA  AT  AG  AC  TA  TT  TG  TC  GA  ...  \\\n",
              "0                aac(6')-Ib_2_M23634  34  33  47  41  20  24  42  31  51  ...   \n",
              "1            aac(6')-Ib11_1_AY136758  33  33  40  40  18  19  43  29  50  ...   \n",
              "2  aac(6')-30-aac(6')-Ib'_1_AJ584652  56  57  75  65  32  40  71  52  86  ...   \n",
              "\n",
              "   Metronidazole  Piperacillin+Clavulanic acid  Formaldehyde  \\\n",
              "0              0                             0             0   \n",
              "1              0                             0             0   \n",
              "2              0                             0             0   \n",
              "\n",
              "   Benzylkonium Chloride  Ethidium Bromide  Chlorhexidine  \\\n",
              "0                      0                 0              0   \n",
              "1                      0                 0              0   \n",
              "2                      0                 0              0   \n",
              "\n",
              "   Cetylpyridinium Chloride  Hydrogen peroxide  Nalidixic acid  Temperature  \n",
              "0                         0                  0               0            0  \n",
              "1                         0                  0               0            0  \n",
              "2                         0                  0               0            0  \n",
              "\n",
              "[3 rows x 459 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-237e94a0-88af-4ebd-9eee-3c8181beea6b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>AA</th>\n",
              "      <th>AT</th>\n",
              "      <th>AG</th>\n",
              "      <th>AC</th>\n",
              "      <th>TA</th>\n",
              "      <th>TT</th>\n",
              "      <th>TG</th>\n",
              "      <th>TC</th>\n",
              "      <th>GA</th>\n",
              "      <th>...</th>\n",
              "      <th>Metronidazole</th>\n",
              "      <th>Piperacillin+Clavulanic acid</th>\n",
              "      <th>Formaldehyde</th>\n",
              "      <th>Benzylkonium Chloride</th>\n",
              "      <th>Ethidium Bromide</th>\n",
              "      <th>Chlorhexidine</th>\n",
              "      <th>Cetylpyridinium Chloride</th>\n",
              "      <th>Hydrogen peroxide</th>\n",
              "      <th>Nalidixic acid</th>\n",
              "      <th>Temperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aac(6')-Ib_2_M23634</td>\n",
              "      <td>34</td>\n",
              "      <td>33</td>\n",
              "      <td>47</td>\n",
              "      <td>41</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>42</td>\n",
              "      <td>31</td>\n",
              "      <td>51</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aac(6')-Ib11_1_AY136758</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>43</td>\n",
              "      <td>29</td>\n",
              "      <td>50</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aac(6')-30-aac(6')-Ib'_1_AJ584652</td>\n",
              "      <td>56</td>\n",
              "      <td>57</td>\n",
              "      <td>75</td>\n",
              "      <td>65</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>71</td>\n",
              "      <td>52</td>\n",
              "      <td>86</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 459 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-237e94a0-88af-4ebd-9eee-3c8181beea6b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-237e94a0-88af-4ebd-9eee-3c8181beea6b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-237e94a0-88af-4ebd-9eee-3c8181beea6b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration options\n",
        "n_samples = df.iloc[:,:]\n",
        "n_features =360 #df.iloc[:,1:337]\n",
        "n_labels = 98#df.iloc[:,337:361]\n",
        "#n_labels = df.iloc[:,361:]\n",
        "n_epochs = 100\n",
        "random_state = 42\n",
        "batch_size = 250\n",
        "verbosity = 1\n",
        "validation_split = 0.2"
      ],
      "metadata": {
        "id": "92ie3y_EpZE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,1:361]\n",
        "y = df.iloc[:,361:]\n"
      ],
      "metadata": {
        "id": "ohny85Dct_bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxC0pYHpMihS",
        "outputId": "10571f9d-afeb-4d18-8750-e6418282ec82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Gentamicin  Tobramycin  Streptomycin  Spectinomycin  Amikacin  Isepamicin  Dibekacin  Kanamycin  Neomycin  Lividomycin  Paromomycin  Ribostamycin  Unknown Aminoglycoside  Butiromycin  Butirosin  Hygromycin  Netilmicin  Apramycin  Sisomicin  Arbekacin  Kasugamycin  Astromicin  Fortimicin  Fluoroquinolone  Ciprofloxacin  Amoxicillin  Amoxicillin+Clavulanic acid  Ampicillin  Ampicillin+Clavulanic acid  Cefepime  Cefixime  Cefotaxime  Cefoxitin  Ceftazidime  Ertapenem  Imipenem  Meropenem  Piperacillin  Piperacillin+Tazobactam  Unknown Beta-lactam  Aztreonam  Cefotaxime+Clavulanic acid  Temocillin  Ticarcillin  Ceftazidime+Avibactam  Penicillin  Ceftriaxone  Ticarcillin+Clavulanic acid  Cephalothin  Ceftiofur  Sulfamethoxazole  Trimethoprim  Fosfomycin.1  Vancomycin  Teicoplanin  Lincomycin  Clindamycin  Dalfopristin  Pristinamycin IIA  Virginiamycin M  Tiamulin  Carbomycin  Erythromycin  Azithromycin  Oleandomycin  Spiramycin  Tylosin  Telithromycin  Unknown Tetracycline  Unknown Quinolone  Unknown Amphenicol  Unknown Rifamycin  Tetracycline.1  Quinupristin  Pristinamycin IA  Virginiamycin S  Linezolid  Chloramphenicol  Florfenicol  Doxycycline  Colistin  Quinupristin+Dalfopristin  Minocycline  Tigecycline  Fusidic acid  Mupirocin  Cephalotin  Rifampicin  Metronidazole  Piperacillin+Clavulanic acid  Formaldehyde  Benzylkonium Chloride  Ethidium Bromide  Chlorhexidine  Cetylpyridinium Chloride  Hydrogen peroxide  Nalidixic acid  Temperature\n",
              "0           0           0             0              0         0           0          0          0         0            0            0             0                       0            0          0           0           0          0          0          0            0           0           0                0              0            0                            0           0                           0         0         0           0          0            0          0         0          0             0                        1                    0          0                           0           0            0                      0           0            0                            0            0          0                 0             0             0           0            0           0            0             0                  0                0         0           0             0             0             0           0        0              0                     0                  0                   0                  0               0             0                 0                0          0                0            0            0         0                          0            0            0             0          0           0           0              0                             0             0                      0                 0              0                         0                  0               0              673\n",
              "                                                                                                                                                                                                                                                                                                                                 1            0                            1           0                           1         0         1           0          1            0          0         0          1             0                        0                    1          0                           0           1            0                      0           1            0                            0            0          0                 0             0             0           0            0           0            0             0                  0                0         0           0             0             0             0           0        0              0                     0                  0                   0                  0               0             0                 0                0          0                0            0            0         0                          0            0            0             0          0           0           0              0                             0             0                      0                 0              0                         0                  0               0              314\n",
              "                                                                                                                                                                                                                                                                                                                                              1                            1           1                           0         0         1           1          1            0          0         0          1             1                        0                    0          0                           0           1            0                      0           0            1                            0            0          0                 0             0             0           0            0           0            0             0                  0                0         0           0             0             0             0           0        0              0                     0                  0                   0                  0               0             0                 0                0          0                0            0            0         0                          0            0            0             0          0           0           0              0                             0             0                      0                 0              0                         0                  0               0              252\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                   1         1         1           1          1            1          1         1          1             1                        0                    0          0                           0           0            0                      0           0            0                            0            0          0                 0             0             0           0            0           0            0             0                  0                0         0           0             0             0             0           0        0              0                     0                  0                   0                  0               0             0                 0                0          0                0            0            0         0                          0            0            0             0          0           0           0              0                             0             0                      0                 0              0                         0                  0               0              167\n",
              "                                                                                                                                                                                                                                                                                                                                              0                            1           0                           0         0         0           0          0            0          0         0          1             0                        0                    0          0                           0           0            0                      1           0            0                            0            0          0                 0             0             0           0            0           0            0             0                  0                0         0           0             0             0             0           0        0              0                     0                  0                   0                  0               0             0                 0                0          0                0            0            0         0                          0            0            0             0          0           0           0              0                             0             0                      0                 0              0                         0                  0               0              139\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ... \n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                   1         0         1           0          1            0          0         0          1             0                        1                    1          0                           0           1            0                      0           1            0                            0            0          0                 0             0             0           0            0           0            0             0                  0                0         0           0             0             0             0           0        0              0                     0                  0                   0                  0               0             0                 0                0          0                0            0            0         0                          0            0            0             0          0           0           0              0                             0             0                      0                 0              0                         0                  0               0                1\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                             1         1           0          1            0          0         0          0             0                        0                    1          0                           0           0            0                      0           0            0                            0            0          0                 0             0             0           0            0           0            0             0                  0                0         0           0             0             0             0           0        0              0                     0                  0                   0                  0               0             0                 0                0          0                0            0            0         0                          0            0            0             0          0           0           0              0                             0             0                      0                 0              0                         0                  0               0                1\n",
              "                                                                                                                                                                                                                                                                                                                                 0            0                            0           0                           0         0         0           0          0            0          0         0          0             0                        0                    0          0                           0           0            0                      0           0            0                            0            0          0                 0             0             0           0            0           0            0             0                  0                0         0           0             0             0             0           0        0              0                     0                  0                   0                  0               0             0                 0                0          0                0            0            0         0                          0            0            0             0          0           0           0              0                             0             0                      0                 0              0                         1                  0               0                1\n",
              "                                                                                                                                                                                                                                                                                                                                 1            0                            1           0                           1         1         1           1          1            0          0         0          0             0                        0                    1          0                           0           0            0                      0           0            0                            0            0          0                 0             0             0           0            0           0            0             0                  0                0         0           0             0             0             0           0        0              0                     0                  0                   0                  0               0             0                 0                0          0                0            0            0         0                          0            0            0             0          0           0           0              0                             0             0                      0                 0              0                         0                  0               0                1\n",
              "1           1           1             1              1         0           0          0          0         0            0            0             0                       0            0          0           0           0          0          0          0            0           0           0                0              0            0                            0           0                           0         0         0           0          0            0          0         0          0             0                        0                    0          0                           0           0            0                      0           0            0                            0            0          0                 0             0             0           0            0           0            0             0                  0                0         0           0             0             0             0           0        0              0                     0                  0                   0                  0               0             0                 0                0          0                0            0            0         0                          0            0            0             0          0           0           0              0                             0             0                      0                 0              0                         0                  0               0                1\n",
              "Length: 215, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us6Fd6Y1My_k",
        "outputId": "cb901ca5-1f35-4862-c5ff-6f51a645ca29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AA   AT   AG   AC   TA   TT   TG   TC   GA   GT   GG   GC   CA   CT   CG   CC   AAA  AAT  AAG  AAC  ATA  ATT  ATG  ATC  AGA  AGT  AGG  AGC  ACA  ACT  ACG  ACC  TAA  TAT  TAG  TAC  TTA  TTT  TTG  TTC  TGA  TGT  TGG  TGC  TCA  TCT  TCG  TCC  GAA  GAT  GAG  GAC  GTA  GTT  GTG  GTC  GGA  GGT  GGG  GGC  GCA  GCT  GCG  GCC  CAA  CAT  CAG  CAC  CTA  CTT  CTG  CTC  CGA  CGT  CGG  CGC  CCA  CCT  CCG  CCC  AAAA  AAAT  AAAG  AAAC  AATA  AATT  AATG  AATC  AAGA  AAGT  AAGG  AAGC  AACA  AACT  AACG  AACC  ATAA  ATAT  ATAG  ATAC  ATTA  ATTT  ATTG  ATTC  ATGA  ATGT  ATGG  ATGC  ATCA  ATCT  ATCG  ATCC  AGAA  AGAT  AGAG  AGAC  AGTA  AGTT  AGTG  AGTC  AGGA  AGGT  AGGG  AGGC  AGCA  AGCT  AGCG  AGCC  ACAA  ACAT  ACAG  ACAC  ACTA  ACTT  ACTG  ACTC  ACGA  ACGT  ACGG  ACGC  ACCA  ACCT  ACCG  ACCC  TAAA  TAAT  TAAG  TAAC  TATA  TATT  TATG  TATC  TAGA  TAGT  TAGG  TAGC  TACA  TACT  TACG  TACC  TTAA  TTAT  TTAG  TTAC  TTTA  TTTT  TTTG  TTTC  TTGA  TTGT  TTGG  TTGC  TTCA  TTCT  TTCG  TTCC  TGAA  TGAT  TGAG  TGAC  TGTA  TGTT  TGTG  TGTC  TGGA  TGGT  TGGG  TGGC  TGCA  TGCT  TGCG  TGCC  TCAA  TCAT  TCAG  TCAC  TCTA  TCTT  TCTG  TCTC  TCGA  TCGT  TCGG  TCGC  TCCA  TCCT  TCCG  TCCC  GAAA  GAAT  GAAG  GAAC  GATA  GATT  GATG  GATC  GAGA  GAGT  GAGG  GAGC  GACA  GACT  GACG  GACC  GTAA  GTAT  GTAG  GTAC  GTTA  GTTT  GTTG  GTTC  GTGA  GTGT  GTGG  GTGC  GTCA  GTCT  GTCG  GTCC  GGAA  GGAT  GGAG  GGAC  GGTA  GGTT  GGTG  GGTC  GGGA  GGGT  GGGG  GGGC  GGCA  GGCT  GGCG  GGCC  GCAA  GCAT  GCAG  GCAC  GCTA  GCTT  GCTG  GCTC  GCGA  GCGT  GCGG  GCGC  GCCA  GCCT  GCCG  GCCC  CAAA  CAAT  CAAG  CAAC  CATA  CATT  CATG  CATC  CAGA  CAGT  CAGG  CAGC  CACA  CACT  CACG  CACC  CTAA  CTAT  CTAG  CTAC  CTTA  CTTT  CTTG  CTTC  CTGA  CTGT  CTGG  CTGC  CTCA  CTCT  CTCG  CTCC  CGAA  CGAT  CGAG  CGAC  CGTA  CGTT  CGTG  CGTC  CGGA  CGGT  CGGG  CGGC  CGCA  CGCT  CGCG  CGCC  CCAA  CCAT  CCAG  CCAC  CCTA  CCTT  CCTG  CCTC  CCGA  CCGT  CCGG  CCGC  CCCA  CCCT  CCCG  CCCC  Aminoglycoside  Quinolone  Beta-lactam  Folate pathway antagonist  Fosfomycin  Glycopeptide  Lincosamide  Streptogramin A  Pleuromutilin  Macrolide  Tetracycline  Amphenicol  Rifamycin  Streptogramin B  Oxazolidinone  Polymyxin  Steroid antibacterial  Pseudomonic acid  Nitroimidazole  Aldehyde  Quaternary Ammonium Compound  Quaternary Ammonium Compounds  Peroxide  Heat\n",
              "104  124  77   41   104  80   66   46   75   53   32   32   62   39   18   22   34   44   30   18   39   39   26   17   21   24   15   15   17   7    9    8    33   30   20   15   30   25   25   11   28   12   14   12   23   10   5    7    28   28   15   3    24   11   8    10   16   14   8    2    13   9    3    7    31   15   11   5    8    16   7    8    9    3    3    3    9    12   1    2    10    15    8     9     16    16    8     3     4     18    3     5     7     2     5     4     13    12    8     7     12    17    7     3     11    5     5     5     11    1     0     4     9     8     3     1     9     6     3     6     6     5     3     1     8     2     0     5     8     4     4     1     0     4     1     2     5     0     2     2     1     4     1     2     14    8     4     5     15    5     5     10    9     3     2     5     7     3     3     2     7     11    6     6     10    14    12    3     13    4     6     2     3     5     1     2     10    9     8     1     7     2     2     1     3     6     5     0     3     5     2     2     12    6     2     3     2     7     1     1     2     2     0     1     3     4     0     0     5     9     12    2     8     11    7     2     5     2     4     4     1     1     1     0     10    10    4     0     3     4     3     1     2     2     1     3     6     1     2     1     6     6     4     0     7     2     3     2     5     2     0     1     1     0     1     0     5     3     4     1     2     2     2     3     2     0     1     0     3     4     0     0     13    10    6     2     1     7     5     2     3     1     6     1     2     1     0     2     2     2     2     2     5     4     3     4     2     1     2     2     2     4     2     0     3     5     0     1     1     1     0     1     2     1     0     0     1     2     0     0     6     2     1     0     4     3     3     2     0     1     0     0     2     0     0     0     0               0          0            0                          0           0             1            1                1              0          0             1           0          0                1              0          0                      0                 0               0         0                             0                              0         0       3\n",
              "     123  77   41   104  80   66   46   74   53   32   33   62   40   18   22   34   44   30   18   39   38   26   17   20   24   15   16   17   7    9    8    33   30   20   15   30   25   25   11   28   12   14   12   23   10   5    7    28   27   15   3    24   11   8    10   16   14   8    2    13   10   3    7    31   15   11   5    8    17   7    8    9    3    3    3    9    12   1    2    10    15    8     9     16    16    8     3     4     18    3     5     7     2     5     4     13    12    8     7     11    17    7     3     11    5     5     5     11    1     0     4     9     7     3     1     9     6     3     6     6     5     3     1     8     3     0     5     8     4     4     1     0     4     1     2     5     0     2     2     1     4     1     2     14    8     4     5     15    5     5     10    8     3     2     6     7     3     3     2     7     11    6     6     10    14    12    3     13    4     6     2     3     5     1     2     10    9     8     1     7     2     2     1     3     6     5     0     3     5     2     2     12    6     2     3     2     7     1     1     2     2     0     1     3     4     0     0     5     9     12    2     8     10    7     2     5     2     4     4     1     1     1     0     10    10    4     0     3     4     3     1     2     2     1     3     6     1     2     1     6     6     4     0     7     2     3     2     5     2     0     1     1     0     1     0     5     3     4     1     2     3     2     3     2     0     1     0     3     4     0     0     13    10    6     2     1     7     5     2     3     1     6     1     2     1     0     2     2     2     2     2     6     4     3     4     2     1     2     2     2     4     2     0     3     5     0     1     1     1     0     1     2     1     0     0     1     2     0     0     6     2     1     0     4     3     3     2     0     1     0     0     2     0     0     0     0               0          0            0                          0           0             1            1                1              0          0             1           0          0                1              0          0                      0                 0               0         0                             0                              0         0       3\n",
              "99   168  127  137  92   98   234  212  203  179  243  333  136  191  355  198  25   27   32   32   20   23   48   77   26   20   46   34   13   15   56   52   20   35   6    30   22   29   19   42   53   31   80   69   26   46   71   66   45   76   31   49   31   31   62   54   57   77   45   97   48   88   106  77   26   28   56   25   19   29   104  35   67   50   105  120  48   39   108  40   8     7     9     9     12    2     7     6     8     5     7     11    7     3     16    6     6     9     0     5     5     7     5     6     11    7     13    17    13    15    29    20    5     10    5     6     4     6     6     4     11    9     12    13    6     12    12    4     4     3     3     3     2     4     5     4     4     7     19    26    10    10    18    14    3     4     4     9     1     2     10    23    0     2     2     1     4     3     9     14    9     10    1     2     10    13    8     9     3     0     10    6     3     9     11    19    14    18    6     15    8     13    3     7     16    17    12    31    14    14    20    19    5     3     9     9     2     7     21    17    17    14    16    24    13    12    24    17    13    9     18    4     5     11    26    34    8     4     8     13    2     7     23    16    2     9     4     16    3     11    2     15    21    7     16    16    7     17    17    12    12    21    12    12    14    7     31    20    12    14    12    19    7     21    46    19    11    9     24    4     11    13    50    11    21    19    30    42    16    11    40    9     9     7     0     10    2     8     4     14    9     9     29    9     1     2     7     14    3     8     1     7     4     9     4     11    18    18    38    28    3     7     13    15    14    27    10    16    5     5     17    23    17    33    21    32    21    39    35    34    6     13    20    9     4     4     25    6     25    10    38    34    9     6     25    3     0               1          0            1                          0           0             0            0                0              0          0             1           0          0                0              0          0                      0                 0               0         1                             1                              0         0       2\n",
              "35   32   45   43   20   21   42   29   50   34   32   46   50   25   43   28   9    6    14   13   4    4    14   10   10   11   8    16   13   8    12   10   3    4    3    10   3    2    12   5    12   2    14   14   9    4    8    8    13   10   16   9    9    10   7    8    11   10   7    8    15   10   12   9    18   11   10   10   4    6    9    6    17   11   7    8    13   3    11   5    1     1     4     4     1     0     4     1     4     2     2     5     5     2     3     3     0     2     1     1     0     0     2     2     5     0     3     6     2     1     3     4     3     1     3     1     3     3     3     2     2     2     0     4     6     2     6     2     3     2     4     4     0     3     4     1     2     2     3     5     5     1     2     2     1     0     0     1     0     0     3     1     1     0     1     1     4     2     3     1     0     0     2     1     1     1     1     0     2     0     3     7     2     0     2     1     1     2     5     4     1     1     0     0     2     5     5     2     2     6     3     3     2     2     0     5     1     1     1     1     4     3     0     1     4     0     3     1     2     3     3     3     0     2     3     5     4     5     2     7     1     1     3     4     1     1     0     7     2     2     3     3     2     1     3     0     3     0     3     2     5     0     3     3     2     4     2     2     3     2     3     2     4     2     2     0     8     5     1     1     2     1     4     3     5     1     4     2     2     2     3     2     6     2     5     5     3     2     3     3     0     4     3     3     3     3     3     2     2     1     0     1     0     0     6     0     3     1     4     1     2     3     0     1     2     7     7     1     3     2     2     4     4     1     2     0     3     0     1     4     5     2     5     1     1     1     0     1     6     5     0     0     2     0     3     1     1               1          0            0                          0           0             0            0                0              0          0             0           0          0                0              0          0                      0                 0               0         0                             0                              0         0       2\n",
              "49   48   72   68   39   36   64   66   70   64   71   129  79   57   127  78   19   7    18   16   13   10   11   14   12   14   20   26   12   7    20   29   15   6    4    13   12   7    10   12   21   5    19   19   21   10   25   10   11   22   14   21   7    17   19   21   14   23   17   30   24   20   48   35   15   11   35   18   7    7    24   18   23   22   28   46   22   20   32   12   7     2     11    5     1     2     1     3     4     5     4     5     1     2     4     9     6     1     3     3     3     1     4     2     4     0     1     6     6     0     6     2     3     3     4     2     1     3     6     4     3     3     5     9     3     2     15    6     2     4     4     2     1     2     3     1     4     3     7     6     6     10    9     4     5     2     1     7     1     1     2     3     1     2     0     1     3     2     3     5     5     1     1     5     3     2     2     2     6     0     2     2     8     2     2     0     6     5     1     8     1     4     0     0     6     5     5     3     1     7     5     6     3     1     10    7     2     0     3     5     6     6     3     10    4     2     1     3     2     3     4     2     10    2     4     5     2     4     3     5     6     1     10    4     3     1     0     3     3     4     4     6     5     2     7     5     6     7     6     2     1     7     6     0     4     5     9     5     5     3     4     9     6     4     12    6     6     3     11    4     1     3     10    5     8     11    9     21    10    4     16    5     11    0     2     2     1     5     2     3     5     3     12    15    2     2     3     10    1     4     0     2     3     2     0     2     6     3     9     6     1     1     11    6     1     7     4     9     1     5     4     12    0     12    7     9     14    7     16    17    4     3     10    5     3     2     7     8     5     2     8     16    2     4     6     4     0               1          0            1                          0           0             0            0                0              0          0             1           0          0                0              0          0                      0                 0               0         1                             1                              0         0       2\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ..\n",
              "41   38   53   47   28   43   57   45   60   41   41   57   50   51   48   38   8    7    15   16   5    10   15   8    14   11   14   13   9    8    12   18   4    9    3    11   4    14   21   16   14   7    19   16   14   11   11   7    20   14   12   14   7    17   10   7    11   15   7    13   13   14   16   12   15   6    23   6    12   14   11   12   20   7    6    14   14   16   7    13   2     0     5     3     1     1     3     2     5     4     4     2     4     2     5     5     0     1     2     2     0     2     5     3     4     4     4     3     1     2     4     1     5     3     3     4     4     2     3     2     2     6     3     3     4     3     4     2     3     0     6     0     2     0     2     4     6     1     2     3     7     2     2     7     2     0     0     1     1     3     5     1     1     0     1     1     0     2     2     7     1     2     0     1     4     2     5     5     4     2     8     7     7     2     3     4     4     2     5     3     0     6     1     1     5     5     4     5     2     4     5     5     6     3     3     2     2     4     2     5     5     2     1     3     1     3     1     2     2     4     6     8     3     4     4     3     3     4     2     3     4     2     4     4     1     3     0     3     0     5     7     4     2     1     2     5     3     3     1     0     5     1     1     4     3     5     4     3     1     2     2     4     4     4     4     1     4     1     6     2     5     3     3     3     7     3     1     7     3     4     1     4     4     3     4     3     0     2     2     2     6     3     7     7     1     2     1     2     2     4     1     5     0     7     3     4     4     1     5     1     3     6     3     2     6     8     3     3     0     4     2     1     3     2     0     1     3     3     5     4     2     2     8     2     3     7     4     2     2     1     2     2     3     7     3     1     0               0          1            0                          0           0             0            0                0              0          0             0           0          0                0              0          0                      0                 0               0         0                             0                              0         0       1\n",
              "     40   34   34   27   41   49   37   41   36   35   45   40   37   39   23   14   11   11   12   6    14   9    11   8    10   7    9    5    12   5    12   6    8    6    6    9    16   11   12   13   7    19   10   14   5    12   4    16   13   5    7    8    11   10   7    10   12   11   13   10   12   16   7    13   6    12   9    4    7    19   5    10   7    9    12   11   6    6    1    5     4     6     3     4     5     1     1     0     4     4     3     1     5     4     2     0     4     1     1     0     10    2     2     4     0     3     2     4     1     4     2     5     2     0     1     0     5     2     3     1     2     2     2     2     4     1     1     1     1     3     0     0     2     8     2     0     3     0     2     5     4     2     1     1     1     1     2     1     1     3     4     1     3     0     2     0     3     1     2     2     4     3     0     5     9     4     7     3     2     3     3     6     1     5     0     4     6     0     3     2     0     4     1     5     2     6     6     1     2     3     4     4     2     5     3     1     1     2     2     4     2     2     4     1     2     1     0     9     3     1     3     1     6     2     4     2     1     0     2     2     2     0     3     2     1     2     3     2     3     4     2     4     1     2     3     3     1     3     0     4     4     1     1     4     3     4     1     2     6     0     3     2     1     9     0     4     1     1     4     3     2     6     1     5     2     4     5     5     0     2     0     3     3     3     4     0     2     2     2     5     2     3     2     2     2     0     4     2     0     0     2     2     3     1     1     2     4     11    2     1     3     0     2     3     1     4     2     2     3     0     2     2     2     3     2     4     5     2     2     4     2     3     2     0     2     3     1     1     0     3     2     0     0     1     0     0               1          0            0                          0           0             0            0                0              0          0             0           0          0                0              0          0                      0                 0               0         0                             0                              0         0       1\n",
              "     41   47   55   30   35   69   30   59   52   56   96   54   36   91   41   12   9    14   11   8    11   16   6    6    9    9    22   14   7    19   15   13   4    2    11   11   4    16   7    21   12   17   17   9    5    14   2    12   19   9    18   7    18   17   7    8    14   13   29   17   21   33   22   10   8    21   15   4    5    17   10   23   15   25   25   14   3    22   10   6     1     8     3     2     2     4     1     0     3     5     6     6     1     2     2     5     1     0     2     3     2     4     2     6     4     4     1     0     2     3     1     3     0     1     2     2     1     4     2     0     1     2     6     4     3     10    5     2     2     3     7     1     3     2     1     7     4     2     5     3     0     7     4     3     2     4     3     0     2     1     1     0     0     0     2     3     2     2     4     6     3     1     1     0     1     3     1     4     3     5     4     3     1     2     1     4     6     3     8     0     5     6     2     1     4     4     8     1     4     3     9     3     0     4     2     1     0     3     1     1     4     4     5     0     0     1     1     6     3     2     1     6     3     8     2     3     2     0     5     4     3     10    1     2     0     1     4     6     2     7     3     7     4     3     6     3     0     4     0     2     2     3     1     2     6     5     1     3     4     4     5     7     5     13    3     5     2     8     2     2     2     8     7     8     4     10    10    5     1     11    5     3     3     0     4     0     4     2     2     4     4     4     9     1     1     5     7     0     0     0     4     2     0     2     1     3     3     5     5     3     2     5     0     3     11    2     7     3     6     4     2     4     5     6     9     5     9     7     5     0     4     6     3     0     0     2     1     6     3     6     7     5     2     3     2     0               0          1            0                          0           0             0            0                0              0          0             0           0          0                0              0          0                      0                 0               0         0                             0                              0         0       1\n",
              "     42   32   53   23   35   62   34   53   30   55   108  51   47   97   56   17   8    8    15   3    10   18   11   7    5    7    13   7    7    23   16   5    8    0    10   11   9    13   8    20   8    14   20   6    6    14   8    14   16   6    16   0    13   11   5    12   8    10   34   24   19   35   28   12   9    18   12   9    9    19   10   14   9    33   38   14   15   23   12   8     5     3     7     0     2     3     3     2     1     2     3     2     1     7     5     2     0     0     1     2     2     4     2     6     3     3     6     1     1     7     2     2     2     1     2     0     2     3     0     1     1     1     4     4     1     4     4     2     1     3     1     4     2     1     0     2     0     8     13    4     4     4     4     4     0     0     1     0     2     3     3     0     0     0     0     1     1     5     3     1     5     0     5     5     3     2     2     1     3     2     7     1     2     3     2     7     1     2     9     0     3     3     2     4     0     2     8     2     5     7     6     1     0     0     5     1     2     2     1     2     0     4     8     0     2     4     2     7     2     2     3     3     3     7     3     1     0     0     5     2     5     5     4     0     0     0     0     2     4     5     2     5     2     3     2     3     1     1     0     2     5     2     3     0     3     4     1     2     0     1     8     9     7     15    3     9     4     8     3     4     2     10    3     8     5     12    9     9     3     10    6     4     1     3     4     0     3     4     2     4     4     5     5     2     0     6     4     2     3     0     4     2     3     2     2     8     0     6     5     1     2     3     4     3     8     1     2     0     5     2     2     5     7     7     14    9     6     10    15    0     4     7     3     0     3     6     6     2     4     7     10    1     6     5     4     0               0          1            0                          0           0             0            0                0              0          0             0           0          0                0              0          0                      0                 0               0         0                             0                              0         0       1\n",
              "374  376  196  131  325  231  181  131  235  127  91   51   144  133  36   56   145  149  90   53   120  111  79   45   94   40   34   24   55   45   10   20   115  99   61   36   101  81   56   43   72   44   49   14   48   36   15   29   110  70   26   26   43   40   26   17   48   30   16   9    14   27   5    5    68   44   16   16   40   48   19   25   17   11   4    4    26   22   6    11   70    63    44    27    48    39    37    21    44    17    18    7     24    20    4     4     49    48    20    15    28    40    26    15    33    20    20    6     19    14    6     6     45    25    14    9     12    15    10    3     17    8     8     1     4     16    2     2     30    17    6     3     16    19    1     9     3     4     2     1     5     7     2     6     57    38    10    7     37    34    23    13    33    11    7     10    13    10    3     10    32    30    23    14    42    29    17    20    20    13    19    4     17    13    3     10    31    27    5     9     16    16    6     8     22    16    7     3     6     5     1     2     27    9     7     5     11    13    7     7     9     3     1     2     13    9     3     4     50    25    24    9     32    20    12    6     10    8     6     4     14    9     1     2     16    14    9     4     11    19    6     4     8     9     7     1     5     5     3     4     24    11    7     6     10    8     7     4     8     5     4     3     3     4     1     1     4     6     0     4     5     7     9     6     2     2     0     1     3     1     0     1     27    21    10    9     15    17    7     5     6     4     3     3     4     6     2     4     17    11    9     3     18    20    6     4     11    3     2     3     7     6     3     9     5     7     3     2     5     1     3     2     1     0     1     2     1     2     1     0     7     12    3     4     8     9     2     3     3     2     1     0     5     5     1     2     0               0          0            0                          0           0             0            0                0              0          0             0           0          0                0              0          0                      1                 0               0         0                             0                              0         0       1\n",
              "Length: 3139, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=random_state)\n"
      ],
      "metadata": {
        "id": "m2ntLSFRuBNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "zBJRpEUw0eMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_dim=n_features))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(n_labels, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "kRUM-QX4vpSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss=binary_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MRZDnJSXv5ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit data to model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=n_epochs,\n",
        "          verbose=verbosity,\n",
        "          validation_split=validation_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-YF-1BbxCiX",
        "outputId": "2e8854ae-8ad3-414d-d2b2-8a3675484783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 36ms/step - loss: 0.8806 - accuracy: 0.0059 - val_loss: 0.2735 - val_accuracy: 0.0024\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2206 - accuracy: 0.0089 - val_loss: 0.1900 - val_accuracy: 0.0474\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1728 - accuracy: 0.0901 - val_loss: 0.1643 - val_accuracy: 0.3104\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1516 - accuracy: 0.1725 - val_loss: 0.1436 - val_accuracy: 0.0877\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1377 - accuracy: 0.1411 - val_loss: 0.1335 - val_accuracy: 0.1540\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1277 - accuracy: 0.1838 - val_loss: 0.1252 - val_accuracy: 0.2417\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1196 - accuracy: 0.1808 - val_loss: 0.1176 - val_accuracy: 0.1635\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1127 - accuracy: 0.1790 - val_loss: 0.1115 - val_accuracy: 0.2654\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1069 - accuracy: 0.2116 - val_loss: 0.1056 - val_accuracy: 0.1919\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1013 - accuracy: 0.2496 - val_loss: 0.1023 - val_accuracy: 0.1659\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0962 - accuracy: 0.2413 - val_loss: 0.0952 - val_accuracy: 0.2464\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0897 - accuracy: 0.2703 - val_loss: 0.0911 - val_accuracy: 0.2962\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0846 - accuracy: 0.3254 - val_loss: 0.0871 - val_accuracy: 0.2464\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0799 - accuracy: 0.2988 - val_loss: 0.0823 - val_accuracy: 0.3602\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0752 - accuracy: 0.3367 - val_loss: 0.0786 - val_accuracy: 0.2915\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0723 - accuracy: 0.3379 - val_loss: 0.0766 - val_accuracy: 0.3033\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0678 - accuracy: 0.3302 - val_loss: 0.0733 - val_accuracy: 0.4194\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0647 - accuracy: 0.4191 - val_loss: 0.0711 - val_accuracy: 0.3483\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0620 - accuracy: 0.3966 - val_loss: 0.0706 - val_accuracy: 0.3223\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0602 - accuracy: 0.4007 - val_loss: 0.0698 - val_accuracy: 0.4194\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0614 - accuracy: 0.3954 - val_loss: 0.0664 - val_accuracy: 0.3768\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0591 - accuracy: 0.4250 - val_loss: 0.0686 - val_accuracy: 0.5332\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0560 - accuracy: 0.4173 - val_loss: 0.0650 - val_accuracy: 0.4573\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0530 - accuracy: 0.4375 - val_loss: 0.0643 - val_accuracy: 0.4976\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0515 - accuracy: 0.4434 - val_loss: 0.0609 - val_accuracy: 0.4621\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0495 - accuracy: 0.4440 - val_loss: 0.0602 - val_accuracy: 0.3910\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0472 - accuracy: 0.5133 - val_loss: 0.0589 - val_accuracy: 0.4787\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0457 - accuracy: 0.4102 - val_loss: 0.0594 - val_accuracy: 0.5403\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0453 - accuracy: 0.5299 - val_loss: 0.0569 - val_accuracy: 0.3934\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0443 - accuracy: 0.4446 - val_loss: 0.0632 - val_accuracy: 0.4431\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0475 - accuracy: 0.4819 - val_loss: 0.0676 - val_accuracy: 0.4716\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0467 - accuracy: 0.4339 - val_loss: 0.0564 - val_accuracy: 0.3483\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0422 - accuracy: 0.4807 - val_loss: 0.0550 - val_accuracy: 0.4289\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0402 - accuracy: 0.4724 - val_loss: 0.0554 - val_accuracy: 0.4313\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0397 - accuracy: 0.4861 - val_loss: 0.0556 - val_accuracy: 0.4408\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0380 - accuracy: 0.4600 - val_loss: 0.0536 - val_accuracy: 0.5024\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0376 - accuracy: 0.4967 - val_loss: 0.0543 - val_accuracy: 0.4787\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0366 - accuracy: 0.5122 - val_loss: 0.0547 - val_accuracy: 0.4905\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0360 - accuracy: 0.4926 - val_loss: 0.0577 - val_accuracy: 0.5427\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0371 - accuracy: 0.5412 - val_loss: 0.0546 - val_accuracy: 0.4171\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0346 - accuracy: 0.4665 - val_loss: 0.0527 - val_accuracy: 0.5403\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0349 - accuracy: 0.5453 - val_loss: 0.0530 - val_accuracy: 0.4360\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0337 - accuracy: 0.5376 - val_loss: 0.0528 - val_accuracy: 0.4076\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0328 - accuracy: 0.5098 - val_loss: 0.0531 - val_accuracy: 0.4834\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0333 - accuracy: 0.5365 - val_loss: 0.0527 - val_accuracy: 0.4668\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0315 - accuracy: 0.4873 - val_loss: 0.0520 - val_accuracy: 0.4929\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0314 - accuracy: 0.5477 - val_loss: 0.0515 - val_accuracy: 0.5095\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0312 - accuracy: 0.5566 - val_loss: 0.0554 - val_accuracy: 0.4147\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0315 - accuracy: 0.5163 - val_loss: 0.0523 - val_accuracy: 0.5498\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0314 - accuracy: 0.5465 - val_loss: 0.0541 - val_accuracy: 0.4384\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0296 - accuracy: 0.5169 - val_loss: 0.0523 - val_accuracy: 0.4573\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0290 - accuracy: 0.5305 - val_loss: 0.0520 - val_accuracy: 0.4360\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0280 - accuracy: 0.5157 - val_loss: 0.0547 - val_accuracy: 0.4668\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0291 - accuracy: 0.5471 - val_loss: 0.0512 - val_accuracy: 0.4479\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 0.5353 - val_loss: 0.0516 - val_accuracy: 0.4905\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0311 - accuracy: 0.5163 - val_loss: 0.0569 - val_accuracy: 0.5450\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0307 - accuracy: 0.5548 - val_loss: 0.0516 - val_accuracy: 0.4005\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0283 - accuracy: 0.5258 - val_loss: 0.0514 - val_accuracy: 0.5142\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0272 - accuracy: 0.5009 - val_loss: 0.0523 - val_accuracy: 0.5190\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0256 - accuracy: 0.5299 - val_loss: 0.0513 - val_accuracy: 0.4455\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0250 - accuracy: 0.5453 - val_loss: 0.0517 - val_accuracy: 0.4763\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0244 - accuracy: 0.5489 - val_loss: 0.0506 - val_accuracy: 0.5047\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.5448 - val_loss: 0.0505 - val_accuracy: 0.4976\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0238 - accuracy: 0.5353 - val_loss: 0.0502 - val_accuracy: 0.5237\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0235 - accuracy: 0.6076 - val_loss: 0.0497 - val_accuracy: 0.4905\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0230 - accuracy: 0.5424 - val_loss: 0.0504 - val_accuracy: 0.4716\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0234 - accuracy: 0.5756 - val_loss: 0.0520 - val_accuracy: 0.5237\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0245 - accuracy: 0.5554 - val_loss: 0.0534 - val_accuracy: 0.5521\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0245 - accuracy: 0.5756 - val_loss: 0.0545 - val_accuracy: 0.4313\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0265 - accuracy: 0.5513 - val_loss: 0.0553 - val_accuracy: 0.4313\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0257 - accuracy: 0.5216 - val_loss: 0.0528 - val_accuracy: 0.4431\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0246 - accuracy: 0.5044 - val_loss: 0.0492 - val_accuracy: 0.4455\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0224 - accuracy: 0.5062 - val_loss: 0.0505 - val_accuracy: 0.5142\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 0.5928 - val_loss: 0.0514 - val_accuracy: 0.4313\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0213 - accuracy: 0.5139 - val_loss: 0.0506 - val_accuracy: 0.5735\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0211 - accuracy: 0.5738 - val_loss: 0.0517 - val_accuracy: 0.5047\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0211 - accuracy: 0.5590 - val_loss: 0.0501 - val_accuracy: 0.4834\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0204 - accuracy: 0.5614 - val_loss: 0.0528 - val_accuracy: 0.5379\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0201 - accuracy: 0.5525 - val_loss: 0.0498 - val_accuracy: 0.4953\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0198 - accuracy: 0.5827 - val_loss: 0.0532 - val_accuracy: 0.5071\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0201 - accuracy: 0.6183 - val_loss: 0.0499 - val_accuracy: 0.4763\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0204 - accuracy: 0.5602 - val_loss: 0.0525 - val_accuracy: 0.5900\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0198 - accuracy: 0.5945 - val_loss: 0.0512 - val_accuracy: 0.5427\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0188 - accuracy: 0.5608 - val_loss: 0.0503 - val_accuracy: 0.5261\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0193 - accuracy: 0.5637 - val_loss: 0.0511 - val_accuracy: 0.5213\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 0.5756 - val_loss: 0.0514 - val_accuracy: 0.6232\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0187 - accuracy: 0.6141 - val_loss: 0.0525 - val_accuracy: 0.4834\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0186 - accuracy: 0.5797 - val_loss: 0.0530 - val_accuracy: 0.5758\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0195 - accuracy: 0.6194 - val_loss: 0.0543 - val_accuracy: 0.5332\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0188 - accuracy: 0.5578 - val_loss: 0.0519 - val_accuracy: 0.5213\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0185 - accuracy: 0.5904 - val_loss: 0.0516 - val_accuracy: 0.5450\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0179 - accuracy: 0.5566 - val_loss: 0.0534 - val_accuracy: 0.5569\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0183 - accuracy: 0.5691 - val_loss: 0.0522 - val_accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0182 - accuracy: 0.5679 - val_loss: 0.0523 - val_accuracy: 0.4858\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0178 - accuracy: 0.5608 - val_loss: 0.0546 - val_accuracy: 0.5166\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0184 - accuracy: 0.5554 - val_loss: 0.0560 - val_accuracy: 0.4905\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0200 - accuracy: 0.5981 - val_loss: 0.0523 - val_accuracy: 0.4810\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0203 - accuracy: 0.5774 - val_loss: 0.0523 - val_accuracy: 0.5190\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0198 - accuracy: 0.5590 - val_loss: 0.0550 - val_accuracy: 0.4076\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0199 - accuracy: 0.5370 - val_loss: 0.0523 - val_accuracy: 0.4502\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb4b640c1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit data to model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=n_epochs,\n",
        "          verbose=verbosity,\n",
        "          validation_split=validation_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L646BXQ4xIOt",
        "outputId": "23dcbcf4-c505-4e6d-efb3-13f2b2ee7ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0175 - accuracy: 0.5388 - val_loss: 0.0515 - val_accuracy: 0.5047\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0178 - accuracy: 0.5311 - val_loss: 0.0540 - val_accuracy: 0.4645\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.5471 - val_loss: 0.0514 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0174 - accuracy: 0.5934 - val_loss: 0.0555 - val_accuracy: 0.4313\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0170 - accuracy: 0.5181 - val_loss: 0.0547 - val_accuracy: 0.4858\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0184 - accuracy: 0.5726 - val_loss: 0.0540 - val_accuracy: 0.4976\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0166 - accuracy: 0.5679 - val_loss: 0.0564 - val_accuracy: 0.5142\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0174 - accuracy: 0.5708 - val_loss: 0.0631 - val_accuracy: 0.4645\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0213 - accuracy: 0.5649 - val_loss: 0.0579 - val_accuracy: 0.6469\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0176 - accuracy: 0.5702 - val_loss: 0.0563 - val_accuracy: 0.4265\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0172 - accuracy: 0.5779 - val_loss: 0.0577 - val_accuracy: 0.5237\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0188 - accuracy: 0.5584 - val_loss: 0.0628 - val_accuracy: 0.5569\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0198 - accuracy: 0.5548 - val_loss: 0.0557 - val_accuracy: 0.4953\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0164 - accuracy: 0.5335 - val_loss: 0.0556 - val_accuracy: 0.5071\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0163 - accuracy: 0.5679 - val_loss: 0.0556 - val_accuracy: 0.4905\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0158 - accuracy: 0.5187 - val_loss: 0.0549 - val_accuracy: 0.5829\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0157 - accuracy: 0.6277 - val_loss: 0.0586 - val_accuracy: 0.4242\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0169 - accuracy: 0.5845 - val_loss: 0.0554 - val_accuracy: 0.5735\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0161 - accuracy: 0.5928 - val_loss: 0.0555 - val_accuracy: 0.4763\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0158 - accuracy: 0.5471 - val_loss: 0.0541 - val_accuracy: 0.5095\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 0.5525 - val_loss: 0.0588 - val_accuracy: 0.5427\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0154 - accuracy: 0.6123 - val_loss: 0.0607 - val_accuracy: 0.4621\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0153 - accuracy: 0.5578 - val_loss: 0.0574 - val_accuracy: 0.4929\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.5643 - val_loss: 0.0577 - val_accuracy: 0.5284\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0152 - accuracy: 0.5714 - val_loss: 0.0580 - val_accuracy: 0.5024\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0145 - accuracy: 0.5625 - val_loss: 0.0576 - val_accuracy: 0.4763\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0148 - accuracy: 0.5631 - val_loss: 0.0567 - val_accuracy: 0.5284\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.5726 - val_loss: 0.0589 - val_accuracy: 0.5355\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.5963 - val_loss: 0.0582 - val_accuracy: 0.5427\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 0.5791 - val_loss: 0.0579 - val_accuracy: 0.4810\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0151 - accuracy: 0.6218 - val_loss: 0.0584 - val_accuracy: 0.5806\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0158 - accuracy: 0.5880 - val_loss: 0.0577 - val_accuracy: 0.5237\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0157 - accuracy: 0.5400 - val_loss: 0.0615 - val_accuracy: 0.5237\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 0.6094 - val_loss: 0.0612 - val_accuracy: 0.4265\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0154 - accuracy: 0.5625 - val_loss: 0.0581 - val_accuracy: 0.5829\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0152 - accuracy: 0.5501 - val_loss: 0.0579 - val_accuracy: 0.5498\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0147 - accuracy: 0.6040 - val_loss: 0.0591 - val_accuracy: 0.4929\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0151 - accuracy: 0.5637 - val_loss: 0.0571 - val_accuracy: 0.5498\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0138 - accuracy: 0.5608 - val_loss: 0.0576 - val_accuracy: 0.5024\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0142 - accuracy: 0.5667 - val_loss: 0.0586 - val_accuracy: 0.6161\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0143 - accuracy: 0.5987 - val_loss: 0.0610 - val_accuracy: 0.4645\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0148 - accuracy: 0.5655 - val_loss: 0.0698 - val_accuracy: 0.5735\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0175 - accuracy: 0.5697 - val_loss: 0.0580 - val_accuracy: 0.4882\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0151 - accuracy: 0.5679 - val_loss: 0.0618 - val_accuracy: 0.4787\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0160 - accuracy: 0.6236 - val_loss: 0.0619 - val_accuracy: 0.5166\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0154 - accuracy: 0.5370 - val_loss: 0.0603 - val_accuracy: 0.4929\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.5661 - val_loss: 0.0589 - val_accuracy: 0.5118\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 0.5418 - val_loss: 0.0613 - val_accuracy: 0.4787\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0133 - accuracy: 0.5779 - val_loss: 0.0627 - val_accuracy: 0.4716\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.5406 - val_loss: 0.0657 - val_accuracy: 0.4431\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.5815 - val_loss: 0.0590 - val_accuracy: 0.5782\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0137 - accuracy: 0.5631 - val_loss: 0.0646 - val_accuracy: 0.4645\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0138 - accuracy: 0.5685 - val_loss: 0.0588 - val_accuracy: 0.5592\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0128 - accuracy: 0.5691 - val_loss: 0.0629 - val_accuracy: 0.4668\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0134 - accuracy: 0.5412 - val_loss: 0.0643 - val_accuracy: 0.5166\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 0.5762 - val_loss: 0.0631 - val_accuracy: 0.5592\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0137 - accuracy: 0.5477 - val_loss: 0.0614 - val_accuracy: 0.5308\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0135 - accuracy: 0.5614 - val_loss: 0.0608 - val_accuracy: 0.4621\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0130 - accuracy: 0.5750 - val_loss: 0.0608 - val_accuracy: 0.4976\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 0.5536 - val_loss: 0.0639 - val_accuracy: 0.5213\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0127 - accuracy: 0.5667 - val_loss: 0.0640 - val_accuracy: 0.6280\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0132 - accuracy: 0.5934 - val_loss: 0.0648 - val_accuracy: 0.4929\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 0.5525 - val_loss: 0.0629 - val_accuracy: 0.5450\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0128 - accuracy: 0.5376 - val_loss: 0.0619 - val_accuracy: 0.5166\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0134 - accuracy: 0.5548 - val_loss: 0.0631 - val_accuracy: 0.4431\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0126 - accuracy: 0.5412 - val_loss: 0.0669 - val_accuracy: 0.5118\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0127 - accuracy: 0.5779 - val_loss: 0.0627 - val_accuracy: 0.5308\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0125 - accuracy: 0.5287 - val_loss: 0.0639 - val_accuracy: 0.5095\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0118 - accuracy: 0.6040 - val_loss: 0.0682 - val_accuracy: 0.6114\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0131 - accuracy: 0.5797 - val_loss: 0.0685 - val_accuracy: 0.4976\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0150 - accuracy: 0.5495 - val_loss: 0.0684 - val_accuracy: 0.4834\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 0.5750 - val_loss: 0.0710 - val_accuracy: 0.4573\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 0.5258 - val_loss: 0.0650 - val_accuracy: 0.4171\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0161 - accuracy: 0.5293 - val_loss: 0.0637 - val_accuracy: 0.5616\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0143 - accuracy: 0.5714 - val_loss: 0.0646 - val_accuracy: 0.4716\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0133 - accuracy: 0.5548 - val_loss: 0.0672 - val_accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0132 - accuracy: 0.5892 - val_loss: 0.0656 - val_accuracy: 0.5474\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0139 - accuracy: 0.5691 - val_loss: 0.0678 - val_accuracy: 0.4905\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 0.5714 - val_loss: 0.0654 - val_accuracy: 0.5403\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0136 - accuracy: 0.5542 - val_loss: 0.0632 - val_accuracy: 0.5142\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 0.5608 - val_loss: 0.0671 - val_accuracy: 0.5047\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0123 - accuracy: 0.5791 - val_loss: 0.0633 - val_accuracy: 0.5095\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0115 - accuracy: 0.5554 - val_loss: 0.0643 - val_accuracy: 0.4787\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0116 - accuracy: 0.5916 - val_loss: 0.0662 - val_accuracy: 0.5166\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0114 - accuracy: 0.5430 - val_loss: 0.0704 - val_accuracy: 0.4858\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0120 - accuracy: 0.5649 - val_loss: 0.0663 - val_accuracy: 0.4976\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0123 - accuracy: 0.5424 - val_loss: 0.0677 - val_accuracy: 0.5640\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0126 - accuracy: 0.5548 - val_loss: 0.0690 - val_accuracy: 0.4787\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0126 - accuracy: 0.5708 - val_loss: 0.0675 - val_accuracy: 0.5427\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0122 - accuracy: 0.5637 - val_loss: 0.0648 - val_accuracy: 0.4645\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0117 - accuracy: 0.6017 - val_loss: 0.0681 - val_accuracy: 0.6351\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0120 - accuracy: 0.5453 - val_loss: 0.0657 - val_accuracy: 0.4550\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0114 - accuracy: 0.5359 - val_loss: 0.0735 - val_accuracy: 0.4739\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0131 - accuracy: 0.5507 - val_loss: 0.0675 - val_accuracy: 0.4929\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0127 - accuracy: 0.5365 - val_loss: 0.0651 - val_accuracy: 0.5166\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0121 - accuracy: 0.5282 - val_loss: 0.0660 - val_accuracy: 0.5047\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0111 - accuracy: 0.5436 - val_loss: 0.0661 - val_accuracy: 0.4834\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0112 - accuracy: 0.5436 - val_loss: 0.0726 - val_accuracy: 0.5711\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0115 - accuracy: 0.5625 - val_loss: 0.0666 - val_accuracy: 0.5237\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0119 - accuracy: 0.5614 - val_loss: 0.0699 - val_accuracy: 0.5071\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb4b62fca50>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate generalization metrics\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU0zf6H31VBe",
        "outputId": "ff75516d-4435-4619-984a-9418ae41950b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.06160896271467209 / Test accuracy: 0.4764196276664734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3z-skKjK1f8i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}