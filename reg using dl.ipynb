{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0386ac8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 14:12:14.167710: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 14:12:15.628133: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-09 14:12:16.315086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-09 14:12:16.315127: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-09 14:12:16.518490: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 14:12:20.761941: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-09 14:12:20.762195: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-09 14:12:20.762209: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "b58c6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", index_col = 0)\n",
    "test = pd.read_csv(\"test.csv\", index_col = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "ea85d685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1                    -0.025067\n",
       "V2                    -0.061585\n",
       "V3                    -0.098421\n",
       "V4                    -0.082355\n",
       "V5                     0.017850\n",
       "                         ...   \n",
       "batch_S               -0.014340\n",
       "batch_T               -0.024370\n",
       "batch_U                0.069351\n",
       "ctnum_median_status    0.758797\n",
       "infection             -0.135144\n",
       "Name: ctnum_random, Length: 74, dtype: float64"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()['ctnum_random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "681c0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train= train.drop(['V1','V2','V3','V4','V5','V8','V12','V20','V22','V27','V31','V34','V36','V38','V39','V41','V42','V13','V14','V37','agenum_random'\n",
    "                  # ,'V44','V45','V48','V50','batch_N', 'batch_O', 'batch_P', 'batch_Q',\n",
    "       #'batch_R', 'batch_S', 'batch_T','batch_H', 'batch_I', 'batch_J', 'batch_K',\n",
    "       #'batch_L','batch_B','batch_C','batch_E','batch_F','batch_G','batch_U', 'batch_M', 'batch_N','ctnum_random','batch_D'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "01c3a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['ctnum_random', 'batch_D'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d0832ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['ctnum_random', 'V19'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "980b28a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test= test.drop(['V1','V2','V3','V4','V5','V8','V12','V20','V22','V27','V31','V34','V36','V38','V39','V41','V42','V13','V14','V37','agenum_random',\n",
    "      #             'V44','V45','V48','V50','batch_N', 'batch_O', 'batch_P', 'batch_Q',\n",
    "      # 'batch_R', 'batch_S', 'batch_T','batch_H', 'batch_I', 'batch_J', 'batch_K',\n",
    "      # 'batch_L','batch_B','batch_C','batch_E','batch_F','batch_G','batch_U', 'batch_M', 'batch_N','ctnum_random','V19'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "69dd40f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['ctnum_random']\n",
    "y_test = test['ctnum_random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "b4c968ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V20', 'V21', 'V22',\n",
       "       'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32',\n",
       "       'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42',\n",
       "       'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'agenum_random',\n",
       "       'batch_A', 'batch_B', 'batch_C', 'batch_E', 'batch_F', 'batch_G',\n",
       "       'batch_H', 'batch_I', 'batch_J', 'batch_K', 'batch_L', 'batch_M',\n",
       "       'batch_N', 'batch_O', 'batch_P', 'batch_Q', 'batch_R', 'batch_S',\n",
       "       'batch_T', 'batch_U', 'ctnum_median_status', 'infection'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "ce014e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V20', 'V21', 'V22',\n",
       "       'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32',\n",
       "       'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42',\n",
       "       'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'agenum_random',\n",
       "       'batch_A', 'batch_B', 'batch_C', 'batch_E', 'batch_F', 'batch_G',\n",
       "       'batch_H', 'batch_I', 'batch_J', 'batch_K', 'batch_L', 'batch_M',\n",
       "       'batch_N', 'batch_O', 'batch_P', 'batch_Q', 'batch_R', 'batch_S',\n",
       "       'batch_T', 'batch_U', 'ctnum_median_status', 'infection'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "f38df784",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_concat = pd.concat([X_train, y_train],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "186a93e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1                    -0.025067\n",
       "V2                    -0.061585\n",
       "V3                    -0.098421\n",
       "V4                    -0.082355\n",
       "V5                     0.017850\n",
       "                         ...   \n",
       "batch_T               -0.024370\n",
       "batch_U                0.069351\n",
       "ctnum_median_status    0.758797\n",
       "infection             -0.135144\n",
       "ctnum_random           1.000000\n",
       "Name: ctnum_random, Length: 73, dtype: float64"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_concat.corr()['ctnum_random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "8fc31f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>batch_N</th>\n",
       "      <th>batch_O</th>\n",
       "      <th>batch_P</th>\n",
       "      <th>batch_Q</th>\n",
       "      <th>batch_R</th>\n",
       "      <th>batch_S</th>\n",
       "      <th>batch_T</th>\n",
       "      <th>batch_U</th>\n",
       "      <th>ctnum_median_status</th>\n",
       "      <th>infection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.416963</td>\n",
       "      <td>0.181283</td>\n",
       "      <td>0.064580</td>\n",
       "      <td>-0.256586</td>\n",
       "      <td>-0.022616</td>\n",
       "      <td>-0.317925</td>\n",
       "      <td>0.376913</td>\n",
       "      <td>0.086584</td>\n",
       "      <td>-0.255495</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.199633</td>\n",
       "      <td>0.206295</td>\n",
       "      <td>0.288382</td>\n",
       "      <td>-0.150975</td>\n",
       "      <td>0.394386</td>\n",
       "      <td>0.075909</td>\n",
       "      <td>-0.368996</td>\n",
       "      <td>0.323212</td>\n",
       "      <td>0.079250</td>\n",
       "      <td>0.018757</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-0.431797</td>\n",
       "      <td>-0.050736</td>\n",
       "      <td>0.030278</td>\n",
       "      <td>-0.117923</td>\n",
       "      <td>0.246983</td>\n",
       "      <td>-0.160531</td>\n",
       "      <td>-0.197276</td>\n",
       "      <td>0.083967</td>\n",
       "      <td>0.028719</td>\n",
       "      <td>-0.148602</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-0.379012</td>\n",
       "      <td>0.039950</td>\n",
       "      <td>0.292831</td>\n",
       "      <td>0.174339</td>\n",
       "      <td>0.256258</td>\n",
       "      <td>-0.020767</td>\n",
       "      <td>-0.409595</td>\n",
       "      <td>0.085018</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>0.117534</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.451459</td>\n",
       "      <td>-0.048828</td>\n",
       "      <td>-0.089349</td>\n",
       "      <td>-0.151467</td>\n",
       "      <td>0.136524</td>\n",
       "      <td>-0.169697</td>\n",
       "      <td>0.116059</td>\n",
       "      <td>-0.235683</td>\n",
       "      <td>-0.048781</td>\n",
       "      <td>0.168612</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.345858</td>\n",
       "      <td>-0.184016</td>\n",
       "      <td>-0.267976</td>\n",
       "      <td>-0.402239</td>\n",
       "      <td>-0.146177</td>\n",
       "      <td>-0.190639</td>\n",
       "      <td>-0.219773</td>\n",
       "      <td>-0.240624</td>\n",
       "      <td>-0.278037</td>\n",
       "      <td>-0.276137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.437532</td>\n",
       "      <td>-0.172444</td>\n",
       "      <td>-0.003209</td>\n",
       "      <td>-0.007867</td>\n",
       "      <td>-0.018803</td>\n",
       "      <td>-0.055248</td>\n",
       "      <td>-0.353687</td>\n",
       "      <td>0.062032</td>\n",
       "      <td>0.058762</td>\n",
       "      <td>-0.226611</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.085456</td>\n",
       "      <td>-0.017223</td>\n",
       "      <td>0.110324</td>\n",
       "      <td>-0.356316</td>\n",
       "      <td>0.245826</td>\n",
       "      <td>-0.166763</td>\n",
       "      <td>0.105081</td>\n",
       "      <td>-0.011678</td>\n",
       "      <td>-0.292295</td>\n",
       "      <td>-0.055272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>-0.398452</td>\n",
       "      <td>-0.338095</td>\n",
       "      <td>-0.451013</td>\n",
       "      <td>-0.261519</td>\n",
       "      <td>-0.053643</td>\n",
       "      <td>-0.221453</td>\n",
       "      <td>-0.169615</td>\n",
       "      <td>-0.414323</td>\n",
       "      <td>-0.213793</td>\n",
       "      <td>-0.310667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.519434</td>\n",
       "      <td>0.146582</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.175046</td>\n",
       "      <td>-0.051197</td>\n",
       "      <td>-0.045824</td>\n",
       "      <td>0.503479</td>\n",
       "      <td>-0.125214</td>\n",
       "      <td>-0.129111</td>\n",
       "      <td>0.234634</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V1        V2        V3        V4        V5        V6        V7  \\\n",
       "418  0.416963  0.181283  0.064580 -0.256586 -0.022616 -0.317925  0.376913   \n",
       "474  0.199633  0.206295  0.288382 -0.150975  0.394386  0.075909 -0.368996   \n",
       "181 -0.431797 -0.050736  0.030278 -0.117923  0.246983 -0.160531 -0.197276   \n",
       "446 -0.379012  0.039950  0.292831  0.174339  0.256258 -0.020767 -0.409595   \n",
       "297  0.451459 -0.048828 -0.089349 -0.151467  0.136524 -0.169697  0.116059   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "31  -0.345858 -0.184016 -0.267976 -0.402239 -0.146177 -0.190639 -0.219773   \n",
       "113 -0.437532 -0.172444 -0.003209 -0.007867 -0.018803 -0.055248 -0.353687   \n",
       "272  0.085456 -0.017223  0.110324 -0.356316  0.245826 -0.166763  0.105081   \n",
       "311 -0.398452 -0.338095 -0.451013 -0.261519 -0.053643 -0.221453 -0.169615   \n",
       "395  0.519434  0.146582  0.000012 -0.175046 -0.051197 -0.045824  0.503479   \n",
       "\n",
       "           V8        V9       V10  ...  batch_N  batch_O  batch_P  batch_Q  \\\n",
       "418  0.086584 -0.255495  0.096489  ...        0        0        0        0   \n",
       "474  0.323212  0.079250  0.018757  ...        0        0        0        0   \n",
       "181  0.083967  0.028719 -0.148602  ...        0        0        0        1   \n",
       "446  0.085018  0.011241  0.117534  ...        0        0        0        0   \n",
       "297 -0.235683 -0.048781  0.168612  ...        0        0        0        0   \n",
       "..        ...       ...       ...  ...      ...      ...      ...      ...   \n",
       "31  -0.240624 -0.278037 -0.276137  ...        0        0        0        0   \n",
       "113  0.062032  0.058762 -0.226611  ...        0        0        0        0   \n",
       "272 -0.011678 -0.292295 -0.055272  ...        0        0        1        0   \n",
       "311 -0.414323 -0.213793 -0.310667  ...        0        0        0        0   \n",
       "395 -0.125214 -0.129111  0.234634  ...        0        0        0        0   \n",
       "\n",
       "     batch_R  batch_S  batch_T  batch_U  ctnum_median_status  infection  \n",
       "418        0        0        1        0                    1          1  \n",
       "474        0        1        0        0                    0          0  \n",
       "181        0        0        0        0                    0          1  \n",
       "446        0        1        0        0                    1          0  \n",
       "297        0        0        0        0                    1          1  \n",
       "..       ...      ...      ...      ...                  ...        ...  \n",
       "31         0        0        0        0                    0          1  \n",
       "113        0        0        0        0                    0          1  \n",
       "272        0        0        0        0                    0          1  \n",
       "311        0        0        0        0                    1          1  \n",
       "395        0        0        0        0                    0          1  \n",
       "\n",
       "[121 rows x 72 columns]"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "3c31a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "30c2cbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(652, 72)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a3b52621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "431bdceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "07fadd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(112, activation = 'relu', input_dim = X_train.shape[1]))\n",
    "#model.add(Dense(64, activation = 'relu'))\n",
    "#model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "bd6fc335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_265 (Dense)           (None, 112)               8176      \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 1)                 113       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,289\n",
      "Trainable params: 8,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "b4419cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error',optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "f1e43cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 431.2144 - val_loss: 439.8659\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 361.0600 - val_loss: 380.5449\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 291.2898 - val_loss: 319.3177\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 222.1038 - val_loss: 259.7809\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 161.0265 - val_loss: 205.9162\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 116.2801 - val_loss: 160.2798\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 88.0735 - val_loss: 127.7071\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 71.4112 - val_loss: 105.9603\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 60.4330 - val_loss: 91.5364\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 52.4629 - val_loss: 79.6763\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 45.6038 - val_loss: 70.1492\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 40.0246 - val_loss: 62.0124\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 35.5854 - val_loss: 55.2334\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 31.8289 - val_loss: 48.8837\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 28.8651 - val_loss: 43.3297\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 26.3241 - val_loss: 39.1656\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24.4109 - val_loss: 35.5915\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 22.6975 - val_loss: 32.3065\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 21.2527 - val_loss: 29.9522\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 19.9551 - val_loss: 27.5818\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 18.8274 - val_loss: 25.7365\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 17.6994 - val_loss: 23.6352\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 16.7243 - val_loss: 22.1672\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 15.8169 - val_loss: 20.6443\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 14.8862 - val_loss: 19.2641\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 14.1372 - val_loss: 18.1436\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 13.3669 - val_loss: 17.2119\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.6308 - val_loss: 16.1932\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 12.0000 - val_loss: 15.2941\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 11.4179 - val_loss: 14.3754\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.7563 - val_loss: 13.7249\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.2421 - val_loss: 12.9841\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.6684 - val_loss: 12.3862\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.2235 - val_loss: 11.7749\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 8.8019 - val_loss: 11.1183\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 8.3003 - val_loss: 10.7699\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.8964 - val_loss: 10.2551\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.5499 - val_loss: 9.8224\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.1772 - val_loss: 9.5366\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 6.8972 - val_loss: 9.2340\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 6.5444 - val_loss: 8.9136\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 6.3698 - val_loss: 8.6059\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.9932 - val_loss: 8.2984\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.7457 - val_loss: 8.0896\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.4742 - val_loss: 7.8830\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.3096 - val_loss: 7.6164\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.0747 - val_loss: 7.4986\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.8658 - val_loss: 7.1938\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.7178 - val_loss: 6.9767\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.5286 - val_loss: 6.9396\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.3552 - val_loss: 6.7255\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.2737 - val_loss: 6.5534\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.0641 - val_loss: 6.4043\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.9240 - val_loss: 6.2846\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.7857 - val_loss: 6.1585\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.6647 - val_loss: 5.9966\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.5142 - val_loss: 5.9435\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.4195 - val_loss: 5.7812\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.3577 - val_loss: 5.7317\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.2441 - val_loss: 5.5489\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.0777 - val_loss: 5.4811\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.9705 - val_loss: 5.3374\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.8690 - val_loss: 5.2532\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.8058 - val_loss: 5.1203\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.7136 - val_loss: 5.1182\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.6195 - val_loss: 5.0003\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5600 - val_loss: 4.8883\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.4824 - val_loss: 4.7470\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.4003 - val_loss: 4.7495\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.3453 - val_loss: 4.5962\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2666 - val_loss: 4.6499\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2037 - val_loss: 4.4103\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.1340 - val_loss: 4.4580\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.0886 - val_loss: 4.4458\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.0263 - val_loss: 4.3652\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.9587 - val_loss: 4.2021\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.9120 - val_loss: 4.1363\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8661 - val_loss: 4.1014\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8117 - val_loss: 4.0229\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7945 - val_loss: 3.9629\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7370 - val_loss: 3.8784\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 1.7070 - val_loss: 3.8448\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.6582 - val_loss: 3.7948\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5999 - val_loss: 3.7646\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5643 - val_loss: 3.8264\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5144 - val_loss: 3.6698\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5042 - val_loss: 3.7040\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.4714 - val_loss: 3.8223\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.4451 - val_loss: 3.4700\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3535 - val_loss: 3.5493\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3555 - val_loss: 3.4364\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3188 - val_loss: 3.4491\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2676 - val_loss: 3.3765\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2419 - val_loss: 3.3358\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2063 - val_loss: 3.4297\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2093 - val_loss: 3.2349\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1751 - val_loss: 3.2413\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1374 - val_loss: 3.3224\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1022 - val_loss: 3.0886\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0836 - val_loss: 3.1933\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs = 100,batch_size = 32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "fa80850d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e06a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0a4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bf73a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a36bc997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    optimizer = hp.Choice('optimizer',values = ['adam','sgd','adadelta'])\n",
    "    model.compile(optimizer = optimizer, loss= 'mse')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d8adf7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project anything/untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from anything/untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,\n",
    "    directory='anything')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0f9e895c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #4\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "rmsrop            |adam              |optimizer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 158, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 146, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"/tmp/ipykernel_2578/621844710.py\", line 6, in build_model\n",
      "    model.compile(optimizer = optimizer, loss= 'mse')\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py\", line 605, in class_and_config_for_serialized_keras_object\n",
      "    raise ValueError(\n",
      "ValueError: Unknown optimizer: rmsrop. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 158, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 146, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"/tmp/ipykernel_2578/621844710.py\", line 6, in build_model\n",
      "    model.compile(optimizer = optimizer, loss= 'mse')\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py\", line 605, in class_and_config_for_serialized_keras_object\n",
      "    raise ValueError(\n",
      "ValueError: Unknown optimizer: rmsrop. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 158, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 146, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"/tmp/ipykernel_2578/621844710.py\", line 6, in build_model\n",
      "    model.compile(optimizer = optimizer, loss= 'mse')\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py\", line 605, in class_and_config_for_serialized_keras_object\n",
      "    raise ValueError(\n",
      "ValueError: Unknown optimizer: rmsrop. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 158, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 146, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"/tmp/ipykernel_2578/621844710.py\", line 6, in build_model\n",
      "    model.compile(optimizer = optimizer, loss= 'mse')\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py\", line 605, in class_and_config_for_serialized_keras_object\n",
      "    raise ValueError(\n",
      "ValueError: Unknown optimizer: rmsrop. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 158, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 146, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"/tmp/ipykernel_2578/621844710.py\", line 6, in build_model\n",
      "    model.compile(optimizer = optimizer, loss= 'mse')\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py\", line 605, in class_and_config_for_serialized_keras_object\n",
      "    raise ValueError(\n",
      "ValueError: Unknown optimizer: rmsrop. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model 4/5\n",
      "Invalid model 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 158, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\", line 146, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"/tmp/ipykernel_2578/621844710.py\", line 6, in build_model\n",
      "    model.compile(optimizer = optimizer, loss= 'mse')\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/abuzar/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py\", line 605, in class_and_config_for_serialized_keras_object\n",
      "    raise ValueError(\n",
      "ValueError: Unknown optimizer: rmsrop. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Too many failed attempts to build model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:158\u001b[0m, in \u001b[0;36mTuner._try_build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_hypermodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:146\u001b[0m, in \u001b[0;36mTuner._build_hypermodel\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m maybe_distribute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_strategy):\n\u001b[0;32m--> 146\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_compile_args(model)\n",
      "Input \u001b[0;32mIn [166]\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mChoice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m,values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madadelta\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py:605\u001b[0m, in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprintable_module_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    607\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject is passed to the `custom_objects` argument. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#registering_the_custom_object for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    611\u001b[0m     )\n\u001b[1;32m    613\u001b[0m cls_config \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown optimizer: rmsrop. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [168]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:183\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 183\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:295\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    294\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 295\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:221\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"For AutoKeras to override.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03mDO NOT REMOVE this function. AutoKeras overrides the function to tune\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    The fit history.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m--> 221\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    223\u001b[0m tuner_utils\u001b[38;5;241m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    224\u001b[0m     results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperModel.fit()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:166\u001b[0m, in \u001b[0;36mTuner._try_build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid model \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (i, MAX_FAIL_STREAK))\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m MAX_FAIL_STREAK:\n\u001b[0;32m--> 166\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many failed attempts to build model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# Stop if `build()` does not return a valid model.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Too many failed attempts to build model."
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs = 5, validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2e15bade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'adam'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c1098ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f7a3a0029d0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2104fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 112)               3248      \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 113       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,361\n",
      "Trainable params: 3,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5ec705c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 1.8141 - val_loss: 9.0863\n",
      "Epoch 8/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4677 - val_loss: 8.9642\n",
      "Epoch 9/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4343 - val_loss: 9.4730\n",
      "Epoch 10/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5537 - val_loss: 9.3772\n",
      "Epoch 11/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 8.4205\n",
      "Epoch 12/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3709 - val_loss: 9.0370\n",
      "Epoch 13/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4619 - val_loss: 9.6004\n",
      "Epoch 14/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.6188 - val_loss: 8.7561\n",
      "Epoch 15/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4929 - val_loss: 9.3585\n",
      "Epoch 16/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 9.5056\n",
      "Epoch 17/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3845 - val_loss: 8.6976\n",
      "Epoch 18/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5682 - val_loss: 9.7799\n",
      "Epoch 19/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3417 - val_loss: 8.6500\n",
      "Epoch 20/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4356 - val_loss: 9.1035\n",
      "Epoch 21/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4464 - val_loss: 8.5448\n",
      "Epoch 22/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4217 - val_loss: 8.6296\n",
      "Epoch 23/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4344 - val_loss: 10.2543\n",
      "Epoch 24/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4878 - val_loss: 9.0195\n",
      "Epoch 25/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3891 - val_loss: 9.1520\n",
      "Epoch 26/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4181 - val_loss: 8.4685\n",
      "Epoch 27/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3102 - val_loss: 9.1749\n",
      "Epoch 28/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4652 - val_loss: 11.4915\n",
      "Epoch 29/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4068 - val_loss: 9.7324\n",
      "Epoch 30/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2733 - val_loss: 9.1446\n",
      "Epoch 31/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4621 - val_loss: 8.3465\n",
      "Epoch 32/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4179 - val_loss: 9.2004\n",
      "Epoch 33/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2922 - val_loss: 8.8609\n",
      "Epoch 34/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5470 - val_loss: 7.9075\n",
      "Epoch 35/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3644 - val_loss: 9.3484\n",
      "Epoch 36/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3927 - val_loss: 8.9887\n",
      "Epoch 37/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4145 - val_loss: 8.9787\n",
      "Epoch 38/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4349 - val_loss: 8.5838\n",
      "Epoch 39/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 8.5897\n",
      "Epoch 40/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5455 - val_loss: 9.1385\n",
      "Epoch 41/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3059 - val_loss: 8.3218\n",
      "Epoch 42/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4891 - val_loss: 9.0884\n",
      "Epoch 43/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3424 - val_loss: 8.4984\n",
      "Epoch 44/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2984 - val_loss: 9.1809\n",
      "Epoch 45/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2901 - val_loss: 9.7148\n",
      "Epoch 46/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4190 - val_loss: 11.6768\n",
      "Epoch 47/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.5098 - val_loss: 8.8656\n",
      "Epoch 48/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2888 - val_loss: 9.5985\n",
      "Epoch 49/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 8.4804\n",
      "Epoch 50/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2848 - val_loss: 9.4961\n",
      "Epoch 51/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4089 - val_loss: 8.9235\n",
      "Epoch 52/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3002 - val_loss: 9.4747\n",
      "Epoch 53/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3067 - val_loss: 8.7938\n",
      "Epoch 54/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4341 - val_loss: 8.7182\n",
      "Epoch 55/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2714 - val_loss: 9.5408\n",
      "Epoch 56/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3385 - val_loss: 10.2279\n",
      "Epoch 57/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3283 - val_loss: 9.9966\n",
      "Epoch 58/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4175 - val_loss: 9.3082\n",
      "Epoch 59/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2956 - val_loss: 8.3525\n",
      "Epoch 60/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3795 - val_loss: 8.7261\n",
      "Epoch 61/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2931 - val_loss: 8.9028\n",
      "Epoch 62/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3132 - val_loss: 8.6873\n",
      "Epoch 63/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4360 - val_loss: 8.7289\n",
      "Epoch 64/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2927 - val_loss: 8.7273\n",
      "Epoch 65/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3369 - val_loss: 8.6543\n",
      "Epoch 66/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4085 - val_loss: 8.5903\n",
      "Epoch 67/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2760 - val_loss: 8.7272\n",
      "Epoch 68/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2795 - val_loss: 8.1101\n",
      "Epoch 69/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2450 - val_loss: 8.5204\n",
      "Epoch 70/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3066 - val_loss: 9.1125\n",
      "Epoch 71/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 8.3901\n",
      "Epoch 72/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3326 - val_loss: 8.5239\n",
      "Epoch 73/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3100 - val_loss: 8.4831\n",
      "Epoch 74/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2346 - val_loss: 8.7332\n",
      "Epoch 75/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4613 - val_loss: 9.1897\n",
      "Epoch 76/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2703 - val_loss: 8.5391\n",
      "Epoch 77/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3109 - val_loss: 9.2989\n",
      "Epoch 78/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2198 - val_loss: 9.1550\n",
      "Epoch 79/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2611 - val_loss: 9.4380\n",
      "Epoch 80/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2642 - val_loss: 8.9381\n",
      "Epoch 81/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4085 - val_loss: 8.8591\n",
      "Epoch 82/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.1874 - val_loss: 9.4170\n",
      "Epoch 83/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3249 - val_loss: 9.4617\n",
      "Epoch 84/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2584 - val_loss: 9.2579\n",
      "Epoch 85/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2137 - val_loss: 9.0897\n",
      "Epoch 86/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.4120 - val_loss: 8.8167\n",
      "Epoch 87/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2222 - val_loss: 9.2947\n",
      "Epoch 88/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2999 - val_loss: 9.0486\n",
      "Epoch 89/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2400 - val_loss: 8.7967\n",
      "Epoch 90/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2318 - val_loss: 8.5196\n",
      "Epoch 91/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2944 - val_loss: 8.5436\n",
      "Epoch 92/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3432 - val_loss: 8.7653\n",
      "Epoch 93/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2442 - val_loss: 9.2308\n",
      "Epoch 94/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2227 - val_loss: 8.4536\n",
      "Epoch 95/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3221 - val_loss: 10.5195\n",
      "Epoch 96/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3177 - val_loss: 8.7650\n",
      "Epoch 97/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2820 - val_loss: 8.9625\n",
      "Epoch 98/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2374 - val_loss: 8.8045\n",
      "Epoch 99/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3389 - val_loss: 8.9715\n",
      "Epoch 100/100\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3172 - val_loss: 8.5701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79e88f9640>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, batch_size = 1, epochs = 100, initial_epoch = 6, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "37926be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d26a1ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    units = hp.Int('units', min_value = 8,max_value = 128)\n",
    "    model.add(Dense(units=units,activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    \n",
    "    #optimizer = hp.Choice('optimizer',values = ['adam','sgd','adadelta'])\n",
    "    model.compile(optimizer = 'adam', loss= 'mse')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b0953aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,\n",
    "    directory = 'mydir2'\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d5355861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 07s]\n",
      "val_loss: 7.7587056159973145\n",
      "\n",
      "Best val_loss So Far: 7.590597629547119\n",
      "Total elapsed time: 00h 00m 37s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs = 100, validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "76be518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 94}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4c959bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "aad38616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2.0838 - val_loss: 7.5404\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.0576 - val_loss: 7.4224\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 2.0179 - val_loss: 7.4310\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.0290 - val_loss: 7.3925\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.9599 - val_loss: 7.3920\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.9586 - val_loss: 7.2520\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.9206 - val_loss: 7.1999\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.8995 - val_loss: 7.1736\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.8610 - val_loss: 7.5930\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.8790 - val_loss: 7.1473\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.8087 - val_loss: 7.0222\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7760 - val_loss: 7.1713\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7355 - val_loss: 7.0559\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7542 - val_loss: 7.0301\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.6971 - val_loss: 6.8376\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6984 - val_loss: 6.9494\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6783 - val_loss: 6.9768\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6446 - val_loss: 6.9029\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6212 - val_loss: 7.0764\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6264 - val_loss: 6.7364\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.5861 - val_loss: 7.0083\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5457 - val_loss: 6.8404\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6047 - val_loss: 6.9957\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5522 - val_loss: 6.8475\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.4995 - val_loss: 6.7885\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.4758 - val_loss: 6.7649\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4559 - val_loss: 6.8805\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4836 - val_loss: 6.7364\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4385 - val_loss: 6.8376\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.4358 - val_loss: 6.7926\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3865 - val_loss: 6.6602\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.4018 - val_loss: 6.7520\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.3755 - val_loss: 6.7833\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3425 - val_loss: 6.6687\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.3355 - val_loss: 6.5591\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3285 - val_loss: 6.6332\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3073 - val_loss: 6.5412\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2904 - val_loss: 6.6768\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2751 - val_loss: 6.6457\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2592 - val_loss: 6.7028\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2505 - val_loss: 6.5013\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2278 - val_loss: 6.5310\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.2435 - val_loss: 6.7697\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2094 - val_loss: 6.4911\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1849 - val_loss: 6.5972\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1965 - val_loss: 6.6326\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1719 - val_loss: 6.5007\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1378 - val_loss: 6.5320\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1601 - val_loss: 6.4113\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1318 - val_loss: 6.6438\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1113 - val_loss: 6.5304\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1311 - val_loss: 6.5681\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1218 - val_loss: 6.5746\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0797 - val_loss: 6.5073\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0584 - val_loss: 6.5214\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0840 - val_loss: 6.4948\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0368 - val_loss: 6.5355\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0405 - val_loss: 6.4546\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0358 - val_loss: 6.6492\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0146 - val_loss: 6.4755\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0316 - val_loss: 6.5025\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0259 - val_loss: 6.6338\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 6.4246\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9727 - val_loss: 6.6533\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9689 - val_loss: 6.2348\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9720 - val_loss: 6.6337\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9484 - val_loss: 6.4922\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9456 - val_loss: 6.6560\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9648 - val_loss: 6.4997\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9397 - val_loss: 6.5203\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9627 - val_loss: 6.3684\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9444 - val_loss: 6.5132\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9551 - val_loss: 6.7317\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 6.6923\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9229 - val_loss: 6.4378\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8884 - val_loss: 6.6279\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8784 - val_loss: 6.4058\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8784 - val_loss: 6.4913\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8566 - val_loss: 6.4786\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8541 - val_loss: 6.4273\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8619 - val_loss: 6.5362\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8490 - val_loss: 6.8018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8457 - val_loss: 6.5268\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8070 - val_loss: 6.4768\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8614 - val_loss: 6.6090\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8230 - val_loss: 6.5321\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7953 - val_loss: 6.3859\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7777 - val_loss: 6.7124\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8129 - val_loss: 6.4067\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7840 - val_loss: 6.4987\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7730 - val_loss: 6.4869\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7631 - val_loss: 6.5232\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7700 - val_loss: 6.4639\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7574 - val_loss: 6.5202\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7584 - val_loss: 6.7158\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7672 - val_loss: 6.6016\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7409 - val_loss: 6.4210\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7566 - val_loss: 6.5974\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7707 - val_loss: 6.5020\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7309 - val_loss: 6.5176\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7087 - val_loss: 6.7052\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7152 - val_loss: 6.2780\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7002 - val_loss: 6.5722\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7033 - val_loss: 6.4172\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6861 - val_loss: 6.4844\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6961 - val_loss: 6.4607\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6665 - val_loss: 6.5177\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6888 - val_loss: 6.5631\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 6.4720\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6482 - val_loss: 6.4972\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6587 - val_loss: 6.5146\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6488 - val_loss: 6.4905\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6568 - val_loss: 6.4049\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6291 - val_loss: 6.4772\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6454 - val_loss: 6.4886\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6164 - val_loss: 6.5501\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6085 - val_loss: 6.5413\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5982 - val_loss: 6.4672\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6143 - val_loss: 6.5859\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6360 - val_loss: 6.6728\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6055 - val_loss: 6.6082\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6049 - val_loss: 6.4606\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5940 - val_loss: 6.5207\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5892 - val_loss: 6.4166\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5977 - val_loss: 6.5923\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5903 - val_loss: 6.5379\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5672 - val_loss: 6.7066\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5646 - val_loss: 6.6222\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5918 - val_loss: 6.5628\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5652 - val_loss: 6.5208\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5556 - val_loss: 6.5540\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5688 - val_loss: 6.6102\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5491 - val_loss: 6.5931\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5368 - val_loss: 6.4506\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5425 - val_loss: 6.6288\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5398 - val_loss: 6.5913\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5066 - val_loss: 6.7196\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5046 - val_loss: 6.7402\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5323 - val_loss: 6.8415\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5119 - val_loss: 6.5851\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5089 - val_loss: 6.5216\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5060 - val_loss: 6.7830\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4967 - val_loss: 6.6851\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 6.8734\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5092 - val_loss: 6.4928\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4930 - val_loss: 6.5667\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4924 - val_loss: 6.6790\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4853 - val_loss: 6.6119\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4689 - val_loss: 6.5785\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4645 - val_loss: 6.6878\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4646 - val_loss: 6.5626\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4631 - val_loss: 6.5933\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4732 - val_loss: 6.7286\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4576 - val_loss: 6.7291\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4475 - val_loss: 6.5928\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4432 - val_loss: 6.7208\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 6.6594\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4290 - val_loss: 6.8354\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4443 - val_loss: 6.8260\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4726 - val_loss: 6.6879\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4276 - val_loss: 6.7862\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4504 - val_loss: 6.7432\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4444 - val_loss: 6.7298\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 7.0329\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 6.9941\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4390 - val_loss: 6.6173\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4083 - val_loss: 6.8358\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4580 - val_loss: 6.7474\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 6.7405\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 6.6917\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4261 - val_loss: 6.7972\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3974 - val_loss: 6.6536\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3765 - val_loss: 6.6853\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3866 - val_loss: 6.9551\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3843 - val_loss: 6.8463\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3794 - val_loss: 6.7380\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3642 - val_loss: 6.8235\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 6.8200\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3810 - val_loss: 6.6972\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 6.6423\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3527 - val_loss: 7.0084\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3557 - val_loss: 6.8249\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3631 - val_loss: 6.8301\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 6.7422\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3670 - val_loss: 6.8561\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3441 - val_loss: 7.1332\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3429 - val_loss: 6.8044\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3473 - val_loss: 6.8192\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3247 - val_loss: 6.9849\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3382 - val_loss: 6.7884\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3333 - val_loss: 6.8831\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3342 - val_loss: 6.9833\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3400 - val_loss: 6.9471\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3308 - val_loss: 6.8772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79ba4613a0>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, batch_size = 32, epochs = 200, initial_epoch = 6, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efe3aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    \n",
    "    for i in range(hp.Int('num_layers', min_value = 1, max_value = 10)):\n",
    "        \n",
    "        \n",
    "        if counter == 0:\n",
    "            \n",
    "            model.add(\n",
    "                Dense(\n",
    "                    hp.Int('units'+ str(i), min_value = 8, max_value = 128,step =8),\n",
    "                    activation = hp.Choice('activation'+str(i), values = ['relu', 'tanh','sigmoid']),\n",
    "                    input_dim = X_train.shape[1]))\n",
    "            model.add(Dropout(hp.Choice('dropout' + str(i), values = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
    "        else:\n",
    "            \n",
    "            model.add(\n",
    "                Dense(\n",
    "                    hp.Int('units' + str(i), min_value = 8, max_value =  128,  step = 8), \n",
    "                    activation = hp.Choice('activation' + str(i), values =['relu', 'tanh','sigmoid']),\n",
    "                )\n",
    "            )\n",
    "            model.add(Dropout(hp.Choice('dropout' + str(i), values = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "    model.add(Dense(1,activation = 'linear'))\n",
    "    model.compile(optimizer = hp.Choice('optimizer', values= ['rmsprop', 'adam','sgd','nadam','adadelta']),\n",
    "                 loss = 'mean_squared_error')\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86bf15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(build_model,\n",
    "                       objective = 'val_loss',\n",
    "                       max_trials = 3,\n",
    "                       directory = 'mydirectx'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9ab59fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 08s]\n",
      "val_loss: 12.106362342834473\n",
      "\n",
      "Best val_loss So Far: 8.762286186218262\n",
      "Total elapsed time: 00h 00m 25s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train,y_train, epochs = 100,validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21cfc50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 9,\n",
       " 'units0': 32,\n",
       " 'activation0': 'relu',\n",
       " 'dropout0': 0.2,\n",
       " 'optimizer': 'rmsprop',\n",
       " 'units1': 56,\n",
       " 'activation1': 'tanh',\n",
       " 'dropout1': 0.2,\n",
       " 'units2': 16,\n",
       " 'activation2': 'relu',\n",
       " 'dropout2': 0.6,\n",
       " 'units3': 120,\n",
       " 'activation3': 'relu',\n",
       " 'dropout3': 0.8,\n",
       " 'units4': 48,\n",
       " 'activation4': 'relu',\n",
       " 'dropout4': 0.9,\n",
       " 'units5': 88,\n",
       " 'activation5': 'tanh',\n",
       " 'dropout5': 0.2,\n",
       " 'units6': 8,\n",
       " 'activation6': 'relu',\n",
       " 'dropout6': 0.1,\n",
       " 'units7': 8,\n",
       " 'activation7': 'relu',\n",
       " 'dropout7': 0.1,\n",
       " 'units8': 8,\n",
       " 'activation8': 'relu',\n",
       " 'dropout8': 0.1}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0398e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8d5448b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/1000\n",
      "21/21 [==============================] - 1s 8ms/step - loss: 18.8169 - val_loss: 10.8364\n",
      "Epoch 102/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 21.2706 - val_loss: 8.2201\n",
      "Epoch 103/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 18.4863 - val_loss: 9.6011\n",
      "Epoch 104/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.8724 - val_loss: 9.6315\n",
      "Epoch 105/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.5367 - val_loss: 9.9372\n",
      "Epoch 106/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 20.4939 - val_loss: 10.0882\n",
      "Epoch 107/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.3882 - val_loss: 10.8002\n",
      "Epoch 108/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 18.5420 - val_loss: 7.5984\n",
      "Epoch 109/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 18.9904 - val_loss: 9.9975\n",
      "Epoch 110/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2344 - val_loss: 12.0384\n",
      "Epoch 111/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 19.1486 - val_loss: 14.2915\n",
      "Epoch 112/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.5143 - val_loss: 13.4250\n",
      "Epoch 113/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.0025 - val_loss: 13.6760\n",
      "Epoch 114/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.6262 - val_loss: 13.8763\n",
      "Epoch 115/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.6186 - val_loss: 14.1998\n",
      "Epoch 116/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.6152 - val_loss: 15.1710\n",
      "Epoch 117/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.0383 - val_loss: 9.1734\n",
      "Epoch 118/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.7488 - val_loss: 10.8921\n",
      "Epoch 119/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.4396 - val_loss: 8.5668\n",
      "Epoch 120/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.4066 - val_loss: 9.5711\n",
      "Epoch 121/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.4911 - val_loss: 11.7828\n",
      "Epoch 122/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.3855 - val_loss: 15.5896\n",
      "Epoch 123/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.9624 - val_loss: 12.9021\n",
      "Epoch 124/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.8293 - val_loss: 7.4831\n",
      "Epoch 125/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.3482 - val_loss: 9.1178\n",
      "Epoch 126/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.8866 - val_loss: 10.5670\n",
      "Epoch 127/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.7907 - val_loss: 10.7610\n",
      "Epoch 128/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.6791 - val_loss: 12.6069\n",
      "Epoch 129/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.2109 - val_loss: 12.3334\n",
      "Epoch 130/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.1795 - val_loss: 10.2412\n",
      "Epoch 131/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.4910 - val_loss: 15.2409\n",
      "Epoch 132/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1551 - val_loss: 12.1928\n",
      "Epoch 133/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.7716 - val_loss: 11.4202\n",
      "Epoch 134/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.3331 - val_loss: 11.7961\n",
      "Epoch 135/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.4878 - val_loss: 9.4813\n",
      "Epoch 136/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.7801 - val_loss: 9.8464\n",
      "Epoch 137/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.2497 - val_loss: 11.8143\n",
      "Epoch 138/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.2214 - val_loss: 12.5787\n",
      "Epoch 139/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.9119 - val_loss: 9.4869\n",
      "Epoch 140/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.8724 - val_loss: 8.9790\n",
      "Epoch 141/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.7334 - val_loss: 9.3341\n",
      "Epoch 142/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.2899 - val_loss: 9.9421\n",
      "Epoch 143/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1569 - val_loss: 9.4603\n",
      "Epoch 144/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.7710 - val_loss: 10.6180\n",
      "Epoch 145/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.2224 - val_loss: 8.8612\n",
      "Epoch 146/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.7182 - val_loss: 11.9717\n",
      "Epoch 147/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.9951 - val_loss: 9.4272\n",
      "Epoch 148/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.8921 - val_loss: 9.8147\n",
      "Epoch 149/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.8793 - val_loss: 12.4588\n",
      "Epoch 150/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.7874 - val_loss: 12.9837\n",
      "Epoch 151/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.7638 - val_loss: 11.6310\n",
      "Epoch 152/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.9219 - val_loss: 10.9742\n",
      "Epoch 153/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.0946 - val_loss: 8.3763\n",
      "Epoch 154/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.6078 - val_loss: 10.0680\n",
      "Epoch 155/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 17.0156 - val_loss: 9.9707\n",
      "Epoch 156/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.7800 - val_loss: 8.1098\n",
      "Epoch 157/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.7279 - val_loss: 8.4191\n",
      "Epoch 158/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.6124 - val_loss: 10.9002\n",
      "Epoch 159/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.5877 - val_loss: 14.0790\n",
      "Epoch 160/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.8658 - val_loss: 9.8431\n",
      "Epoch 161/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.7204 - val_loss: 7.7813\n",
      "Epoch 162/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.1238 - val_loss: 7.1349\n",
      "Epoch 163/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.0614 - val_loss: 11.1895\n",
      "Epoch 164/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.1848 - val_loss: 11.4036\n",
      "Epoch 165/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.9670 - val_loss: 10.4117\n",
      "Epoch 166/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.3419 - val_loss: 8.8347\n",
      "Epoch 167/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.2863 - val_loss: 13.3068\n",
      "Epoch 168/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.9319 - val_loss: 15.1816\n",
      "Epoch 169/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.2703 - val_loss: 9.3665\n",
      "Epoch 170/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.5719 - val_loss: 12.8641\n",
      "Epoch 171/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.5454 - val_loss: 10.9925\n",
      "Epoch 172/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 16.0124 - val_loss: 7.1172\n",
      "Epoch 173/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.3225 - val_loss: 10.8075\n",
      "Epoch 174/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.9175 - val_loss: 6.7403\n",
      "Epoch 175/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.5455 - val_loss: 8.2014\n",
      "Epoch 176/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.8692 - val_loss: 12.2351\n",
      "Epoch 177/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.5202 - val_loss: 14.1394\n",
      "Epoch 178/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.6793 - val_loss: 8.7097\n",
      "Epoch 179/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.1013 - val_loss: 9.2818\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 13.8198 - val_loss: 11.9214\n",
      "Epoch 181/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.0045 - val_loss: 9.0311\n",
      "Epoch 182/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 16.4226 - val_loss: 9.1358\n",
      "Epoch 183/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.2019 - val_loss: 10.5780\n",
      "Epoch 184/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.2111 - val_loss: 10.1087\n",
      "Epoch 185/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.9045 - val_loss: 8.5531\n",
      "Epoch 186/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.3118 - val_loss: 11.0982\n",
      "Epoch 187/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.9153 - val_loss: 14.2047\n",
      "Epoch 188/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.6294 - val_loss: 8.2152\n",
      "Epoch 189/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.0143 - val_loss: 11.9407\n",
      "Epoch 190/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.6081 - val_loss: 11.6460\n",
      "Epoch 191/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.6994 - val_loss: 10.0280\n",
      "Epoch 192/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.3855 - val_loss: 10.8295\n",
      "Epoch 193/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.8370 - val_loss: 8.3548\n",
      "Epoch 194/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.9656 - val_loss: 9.0999\n",
      "Epoch 195/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.2261 - val_loss: 12.4215\n",
      "Epoch 196/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.4873 - val_loss: 10.4117\n",
      "Epoch 197/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.0240 - val_loss: 11.5520\n",
      "Epoch 198/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.1809 - val_loss: 9.6031\n",
      "Epoch 199/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 14.2212 - val_loss: 10.1732\n",
      "Epoch 200/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.9759 - val_loss: 16.6456\n",
      "Epoch 201/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.0095 - val_loss: 11.3859\n",
      "Epoch 202/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.6939 - val_loss: 9.1210\n",
      "Epoch 203/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.8932 - val_loss: 10.0829\n",
      "Epoch 204/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.0318 - val_loss: 8.8769\n",
      "Epoch 205/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.5269 - val_loss: 9.3963\n",
      "Epoch 206/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.1776 - val_loss: 7.7720\n",
      "Epoch 207/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.8991 - val_loss: 10.1964\n",
      "Epoch 208/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.3349 - val_loss: 10.5555\n",
      "Epoch 209/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9837 - val_loss: 11.6671\n",
      "Epoch 210/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.5847 - val_loss: 10.9309\n",
      "Epoch 211/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.8238 - val_loss: 10.4830\n",
      "Epoch 212/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.9679 - val_loss: 7.6624\n",
      "Epoch 213/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.9739 - val_loss: 8.0518\n",
      "Epoch 214/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.9708 - val_loss: 8.2329\n",
      "Epoch 215/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.0298 - val_loss: 8.8366\n",
      "Epoch 216/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.6937 - val_loss: 11.0114\n",
      "Epoch 217/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.8011 - val_loss: 8.4896\n",
      "Epoch 218/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.1744 - val_loss: 9.0995\n",
      "Epoch 219/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.1126 - val_loss: 10.4118\n",
      "Epoch 220/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.1820 - val_loss: 10.3328\n",
      "Epoch 221/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.2869 - val_loss: 9.7681\n",
      "Epoch 222/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.3773 - val_loss: 8.9696\n",
      "Epoch 223/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.1398 - val_loss: 9.5040\n",
      "Epoch 224/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.3754 - val_loss: 11.2578\n",
      "Epoch 225/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.6400 - val_loss: 10.8532\n",
      "Epoch 226/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.7938 - val_loss: 10.0904\n",
      "Epoch 227/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.9779 - val_loss: 10.6594\n",
      "Epoch 228/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.3191 - val_loss: 7.8217\n",
      "Epoch 229/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.6242 - val_loss: 11.1661\n",
      "Epoch 230/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.2258 - val_loss: 10.7511\n",
      "Epoch 231/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.5112 - val_loss: 11.8614\n",
      "Epoch 232/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.8840 - val_loss: 10.4298\n",
      "Epoch 233/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.8095 - val_loss: 11.8659\n",
      "Epoch 234/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.0971 - val_loss: 7.7426\n",
      "Epoch 235/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.0092 - val_loss: 7.8003\n",
      "Epoch 236/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.8142 - val_loss: 10.4324\n",
      "Epoch 237/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.2288 - val_loss: 6.0761\n",
      "Epoch 238/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.0120 - val_loss: 13.5195\n",
      "Epoch 239/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.6841 - val_loss: 11.3700\n",
      "Epoch 240/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.9916 - val_loss: 9.1864\n",
      "Epoch 241/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.5478 - val_loss: 6.7742\n",
      "Epoch 242/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.7887 - val_loss: 7.1217\n",
      "Epoch 243/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.4122 - val_loss: 8.0784\n",
      "Epoch 244/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.7362 - val_loss: 7.5320\n",
      "Epoch 245/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.7041 - val_loss: 8.5690\n",
      "Epoch 246/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.7331 - val_loss: 7.6321\n",
      "Epoch 247/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.4807 - val_loss: 8.6651\n",
      "Epoch 248/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.4453 - val_loss: 10.3786\n",
      "Epoch 249/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 15.7251 - val_loss: 9.2544\n",
      "Epoch 250/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.5890 - val_loss: 10.7607\n",
      "Epoch 251/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.8015 - val_loss: 8.5572\n",
      "Epoch 252/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.5610 - val_loss: 8.5660\n",
      "Epoch 253/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.3230 - val_loss: 6.6797\n",
      "Epoch 254/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 13.0894 - val_loss: 7.5692\n",
      "Epoch 255/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.2987 - val_loss: 6.6588\n",
      "Epoch 256/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.1731 - val_loss: 6.9986\n",
      "Epoch 257/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.9486 - val_loss: 11.6546\n",
      "Epoch 258/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.9535 - val_loss: 7.2626\n",
      "Epoch 259/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 13.9806 - val_loss: 9.6039\n",
      "Epoch 260/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.0889 - val_loss: 10.6910\n",
      "Epoch 261/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.2131 - val_loss: 6.3482\n",
      "Epoch 262/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.4207 - val_loss: 7.7306\n",
      "Epoch 263/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.4015 - val_loss: 9.0409\n",
      "Epoch 264/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.1793 - val_loss: 9.0111\n",
      "Epoch 265/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.7885 - val_loss: 7.6920\n",
      "Epoch 266/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.4659 - val_loss: 8.6118\n",
      "Epoch 267/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.4938 - val_loss: 8.7389\n",
      "Epoch 268/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.8043 - val_loss: 10.1897\n",
      "Epoch 269/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.6979 - val_loss: 10.3683\n",
      "Epoch 270/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.7880 - val_loss: 10.9693\n",
      "Epoch 271/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.0247 - val_loss: 7.1575\n",
      "Epoch 272/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.6362 - val_loss: 7.2107\n",
      "Epoch 273/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.8927 - val_loss: 8.0931\n",
      "Epoch 274/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.9785 - val_loss: 9.5197\n",
      "Epoch 275/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.4247 - val_loss: 8.4089\n",
      "Epoch 276/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.1322 - val_loss: 8.4102\n",
      "Epoch 277/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.0355 - val_loss: 7.6799\n",
      "Epoch 278/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.7571 - val_loss: 9.3876\n",
      "Epoch 279/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.6244 - val_loss: 10.6852\n",
      "Epoch 280/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.2672 - val_loss: 10.5332\n",
      "Epoch 281/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.4545 - val_loss: 7.8357\n",
      "Epoch 282/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.1363 - val_loss: 10.4876\n",
      "Epoch 283/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.7601 - val_loss: 9.8291\n",
      "Epoch 284/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.1969 - val_loss: 11.2453\n",
      "Epoch 285/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.0661 - val_loss: 6.3085\n",
      "Epoch 286/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.1329 - val_loss: 7.0200\n",
      "Epoch 287/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.1489 - val_loss: 8.3594\n",
      "Epoch 288/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.2079 - val_loss: 7.0459\n",
      "Epoch 289/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.9949 - val_loss: 7.9643\n",
      "Epoch 290/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.6831 - val_loss: 6.9874\n",
      "Epoch 291/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.2803 - val_loss: 9.7278\n",
      "Epoch 292/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.6742 - val_loss: 7.5020\n",
      "Epoch 293/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.4236 - val_loss: 13.4113\n",
      "Epoch 294/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.1599 - val_loss: 7.0261\n",
      "Epoch 295/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.1724 - val_loss: 6.9722\n",
      "Epoch 296/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.6354 - val_loss: 6.9360\n",
      "Epoch 297/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.9146 - val_loss: 9.6079\n",
      "Epoch 298/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.2904 - val_loss: 11.2037\n",
      "Epoch 299/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.8370 - val_loss: 12.0008\n",
      "Epoch 300/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.9378 - val_loss: 8.7400\n",
      "Epoch 301/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.2020 - val_loss: 6.5016\n",
      "Epoch 302/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.6465 - val_loss: 10.4675\n",
      "Epoch 303/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.4389 - val_loss: 7.2562\n",
      "Epoch 304/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.3468 - val_loss: 9.0068\n",
      "Epoch 305/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 13.2398 - val_loss: 8.8432\n",
      "Epoch 306/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.1679 - val_loss: 8.2795\n",
      "Epoch 307/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.8376 - val_loss: 7.7443\n",
      "Epoch 308/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.5419 - val_loss: 6.4186\n",
      "Epoch 309/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.6427 - val_loss: 6.7551\n",
      "Epoch 310/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.6465 - val_loss: 8.6647\n",
      "Epoch 311/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.6602 - val_loss: 10.6522\n",
      "Epoch 312/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.8407 - val_loss: 9.0128\n",
      "Epoch 313/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.8656 - val_loss: 10.9304\n",
      "Epoch 314/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.3564 - val_loss: 8.1404\n",
      "Epoch 315/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.1026 - val_loss: 7.1547\n",
      "Epoch 316/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.8738 - val_loss: 8.3783\n",
      "Epoch 317/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.5811 - val_loss: 8.8969\n",
      "Epoch 318/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.9917 - val_loss: 10.7223\n",
      "Epoch 319/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.4343 - val_loss: 9.5747\n",
      "Epoch 320/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.5134 - val_loss: 6.9712\n",
      "Epoch 321/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.1653 - val_loss: 9.0131\n",
      "Epoch 322/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.9205 - val_loss: 8.8089\n",
      "Epoch 323/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.9556 - val_loss: 7.9860\n",
      "Epoch 324/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.5999 - val_loss: 8.1922\n",
      "Epoch 325/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.2859 - val_loss: 7.6823\n",
      "Epoch 326/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.6104 - val_loss: 6.5125\n",
      "Epoch 327/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.1202 - val_loss: 8.1076\n",
      "Epoch 328/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.2918 - val_loss: 9.2610\n",
      "Epoch 329/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.0608 - val_loss: 7.0180\n",
      "Epoch 330/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.2321 - val_loss: 10.1698\n",
      "Epoch 331/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.9454 - val_loss: 8.1512\n",
      "Epoch 332/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.4710 - val_loss: 7.9194\n",
      "Epoch 333/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.6105 - val_loss: 7.1579\n",
      "Epoch 334/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.0893 - val_loss: 7.2605\n",
      "Epoch 335/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.9751 - val_loss: 8.6264\n",
      "Epoch 336/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 12.3335 - val_loss: 8.4643\n",
      "Epoch 337/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.8664 - val_loss: 7.1424\n",
      "Epoch 338/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 10.2392 - val_loss: 7.8582\n",
      "Epoch 339/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.7443 - val_loss: 7.5566\n",
      "Epoch 340/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.8555 - val_loss: 9.2969\n",
      "Epoch 341/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.7239 - val_loss: 7.6255\n",
      "Epoch 342/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.0827 - val_loss: 6.0695\n",
      "Epoch 343/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0426 - val_loss: 9.5246\n",
      "Epoch 344/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.3561 - val_loss: 9.6596\n",
      "Epoch 345/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.8268 - val_loss: 7.9352\n",
      "Epoch 346/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6303 - val_loss: 8.7568\n",
      "Epoch 347/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.7902 - val_loss: 7.1492\n",
      "Epoch 348/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.6255 - val_loss: 9.3829\n",
      "Epoch 349/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 12.2968 - val_loss: 8.4534\n",
      "Epoch 350/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.8910 - val_loss: 7.5503\n",
      "Epoch 351/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.5754 - val_loss: 9.5650\n",
      "Epoch 352/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.5920 - val_loss: 8.3086\n",
      "Epoch 353/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.8103 - val_loss: 7.8071\n",
      "Epoch 354/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.7227 - val_loss: 8.9578\n",
      "Epoch 355/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8425 - val_loss: 6.4894\n",
      "Epoch 356/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.5010 - val_loss: 8.7097\n",
      "Epoch 357/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.4260 - val_loss: 8.6296\n",
      "Epoch 358/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.0073 - val_loss: 10.2379\n",
      "Epoch 359/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.7419 - val_loss: 8.5543\n",
      "Epoch 360/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.6402 - val_loss: 6.5615\n",
      "Epoch 361/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8645 - val_loss: 7.2192\n",
      "Epoch 362/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.5394 - val_loss: 8.1135\n",
      "Epoch 363/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.2552 - val_loss: 8.8441\n",
      "Epoch 364/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.0457 - val_loss: 9.3618\n",
      "Epoch 365/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.3791 - val_loss: 5.6905\n",
      "Epoch 366/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.9801 - val_loss: 6.5293\n",
      "Epoch 367/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.0020 - val_loss: 9.1067\n",
      "Epoch 368/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.8905 - val_loss: 6.4910\n",
      "Epoch 369/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.9279 - val_loss: 6.1361\n",
      "Epoch 370/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.1883 - val_loss: 6.2455\n",
      "Epoch 371/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.9357 - val_loss: 8.2278\n",
      "Epoch 372/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.6898 - val_loss: 7.5099\n",
      "Epoch 373/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.6982 - val_loss: 8.8761\n",
      "Epoch 374/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0997 - val_loss: 7.3530\n",
      "Epoch 375/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4049 - val_loss: 7.4112\n",
      "Epoch 376/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.4652 - val_loss: 7.8171\n",
      "Epoch 377/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.3555 - val_loss: 7.1892\n",
      "Epoch 378/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.3907 - val_loss: 6.7844\n",
      "Epoch 379/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.2315 - val_loss: 8.4448\n",
      "Epoch 380/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4425 - val_loss: 5.7031\n",
      "Epoch 381/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.5567 - val_loss: 8.1059\n",
      "Epoch 382/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0271 - val_loss: 8.7833\n",
      "Epoch 383/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.2243 - val_loss: 7.4017\n",
      "Epoch 384/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 11.8005 - val_loss: 5.5117\n",
      "Epoch 385/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.7344 - val_loss: 5.5032\n",
      "Epoch 386/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.2619 - val_loss: 7.7401\n",
      "Epoch 387/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.1756 - val_loss: 5.9933\n",
      "Epoch 388/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.8647 - val_loss: 7.1163\n",
      "Epoch 389/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.7633 - val_loss: 5.3733\n",
      "Epoch 390/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.2815 - val_loss: 6.7459\n",
      "Epoch 391/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.5230 - val_loss: 6.0047\n",
      "Epoch 392/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5045 - val_loss: 6.3522\n",
      "Epoch 393/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.9320 - val_loss: 6.6553\n",
      "Epoch 394/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.8305 - val_loss: 7.1152\n",
      "Epoch 395/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0928 - val_loss: 6.4925\n",
      "Epoch 396/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.3591 - val_loss: 7.1911\n",
      "Epoch 397/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.3435 - val_loss: 7.9977\n",
      "Epoch 398/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8182 - val_loss: 8.5881\n",
      "Epoch 399/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5808 - val_loss: 8.7603\n",
      "Epoch 400/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.5072 - val_loss: 6.1355\n",
      "Epoch 401/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4286 - val_loss: 6.6241\n",
      "Epoch 402/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1633 - val_loss: 8.2152\n",
      "Epoch 403/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3083 - val_loss: 8.8279\n",
      "Epoch 404/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1386 - val_loss: 6.5476\n",
      "Epoch 405/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.1501 - val_loss: 6.5635\n",
      "Epoch 406/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.2810 - val_loss: 6.0737\n",
      "Epoch 407/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.4547 - val_loss: 7.7981\n",
      "Epoch 408/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4766 - val_loss: 8.9786\n",
      "Epoch 409/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3390 - val_loss: 6.5859\n",
      "Epoch 410/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0424 - val_loss: 7.2638\n",
      "Epoch 411/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3377 - val_loss: 6.6401\n",
      "Epoch 412/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0877 - val_loss: 7.4224\n",
      "Epoch 413/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.6894 - val_loss: 5.7922\n",
      "Epoch 414/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2326 - val_loss: 7.1933\n",
      "Epoch 415/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1134 - val_loss: 7.0058\n",
      "Epoch 416/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.3164 - val_loss: 6.7506\n",
      "Epoch 417/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.5115 - val_loss: 7.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.5621 - val_loss: 7.8473\n",
      "Epoch 419/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7350 - val_loss: 8.5753\n",
      "Epoch 420/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8511 - val_loss: 8.6753\n",
      "Epoch 421/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.4207 - val_loss: 6.5514\n",
      "Epoch 422/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.6309 - val_loss: 7.4321\n",
      "Epoch 423/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3866 - val_loss: 6.5030\n",
      "Epoch 424/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1141 - val_loss: 7.7406\n",
      "Epoch 425/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4829 - val_loss: 7.8565\n",
      "Epoch 426/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.8633 - val_loss: 7.6690\n",
      "Epoch 427/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8098 - val_loss: 7.4996\n",
      "Epoch 428/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4123 - val_loss: 7.4135\n",
      "Epoch 429/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6482 - val_loss: 7.3722\n",
      "Epoch 430/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.0632 - val_loss: 7.6132\n",
      "Epoch 431/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.2801 - val_loss: 6.0724\n",
      "Epoch 432/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3523 - val_loss: 8.5028\n",
      "Epoch 433/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.4567 - val_loss: 6.3788\n",
      "Epoch 434/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8506 - val_loss: 7.7596\n",
      "Epoch 435/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.1812 - val_loss: 7.1874\n",
      "Epoch 436/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3006 - val_loss: 6.8371\n",
      "Epoch 437/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2065 - val_loss: 7.6467\n",
      "Epoch 438/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3218 - val_loss: 7.0502\n",
      "Epoch 439/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 11.0093 - val_loss: 8.4182\n",
      "Epoch 440/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.0993 - val_loss: 7.0000\n",
      "Epoch 441/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5419 - val_loss: 6.5225\n",
      "Epoch 442/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0864 - val_loss: 6.1979\n",
      "Epoch 443/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.6098 - val_loss: 5.5532\n",
      "Epoch 444/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5712 - val_loss: 6.5636\n",
      "Epoch 445/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9507 - val_loss: 7.3296\n",
      "Epoch 446/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.6871 - val_loss: 7.5809\n",
      "Epoch 447/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.1964 - val_loss: 8.1568\n",
      "Epoch 448/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0541 - val_loss: 5.7074\n",
      "Epoch 449/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3934 - val_loss: 7.2552\n",
      "Epoch 450/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.7646 - val_loss: 6.5663\n",
      "Epoch 451/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.0013 - val_loss: 5.6046\n",
      "Epoch 452/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.8684 - val_loss: 5.9051\n",
      "Epoch 453/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5848 - val_loss: 7.0818\n",
      "Epoch 454/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8159 - val_loss: 5.6799\n",
      "Epoch 455/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2011 - val_loss: 6.7823\n",
      "Epoch 456/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.1436 - val_loss: 6.5385\n",
      "Epoch 457/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3942 - val_loss: 5.8550\n",
      "Epoch 458/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9906 - val_loss: 6.9223\n",
      "Epoch 459/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5101 - val_loss: 6.0022\n",
      "Epoch 460/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7854 - val_loss: 5.7814\n",
      "Epoch 461/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.3480 - val_loss: 6.8371\n",
      "Epoch 462/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.3701 - val_loss: 5.6603\n",
      "Epoch 463/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.0867 - val_loss: 6.1625\n",
      "Epoch 464/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7281 - val_loss: 5.3422\n",
      "Epoch 465/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.8658 - val_loss: 7.4929\n",
      "Epoch 466/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.7473 - val_loss: 6.1060\n",
      "Epoch 467/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.0520 - val_loss: 8.7647\n",
      "Epoch 468/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1101 - val_loss: 6.8175\n",
      "Epoch 469/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6836 - val_loss: 6.3013\n",
      "Epoch 470/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6024 - val_loss: 6.0507\n",
      "Epoch 471/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.2029 - val_loss: 6.0370\n",
      "Epoch 472/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.8131 - val_loss: 7.0771\n",
      "Epoch 473/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.6173 - val_loss: 5.5903\n",
      "Epoch 474/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5243 - val_loss: 7.1864\n",
      "Epoch 475/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.0730 - val_loss: 5.6072\n",
      "Epoch 476/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4568 - val_loss: 6.2106\n",
      "Epoch 477/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.6922 - val_loss: 6.2725\n",
      "Epoch 478/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 10.2425 - val_loss: 6.3385\n",
      "Epoch 479/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.8745 - val_loss: 9.0648\n",
      "Epoch 480/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.6746 - val_loss: 5.8262\n",
      "Epoch 481/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.3183 - val_loss: 6.5692\n",
      "Epoch 482/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4788 - val_loss: 5.2027\n",
      "Epoch 483/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.8606 - val_loss: 7.2569\n",
      "Epoch 484/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.0836 - val_loss: 6.2571\n",
      "Epoch 485/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2039 - val_loss: 6.2624\n",
      "Epoch 486/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.0077 - val_loss: 5.8689\n",
      "Epoch 487/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5617 - val_loss: 5.6581\n",
      "Epoch 488/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.0434 - val_loss: 5.0345\n",
      "Epoch 489/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7084 - val_loss: 7.1522\n",
      "Epoch 490/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9332 - val_loss: 5.7498\n",
      "Epoch 491/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4085 - val_loss: 6.0074\n",
      "Epoch 492/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5722 - val_loss: 6.3950\n",
      "Epoch 493/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.8547 - val_loss: 6.3303\n",
      "Epoch 494/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2107 - val_loss: 6.7383\n",
      "Epoch 495/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6673 - val_loss: 7.1241\n",
      "Epoch 496/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2309 - val_loss: 5.1593\n",
      "Epoch 497/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2988 - val_loss: 6.9935\n",
      "Epoch 498/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2002 - val_loss: 5.3827\n",
      "Epoch 499/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5346 - val_loss: 6.3515\n",
      "Epoch 500/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4308 - val_loss: 5.4794\n",
      "Epoch 501/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7390 - val_loss: 6.1711\n",
      "Epoch 502/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4494 - val_loss: 6.3992\n",
      "Epoch 503/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6376 - val_loss: 5.3830\n",
      "Epoch 504/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6931 - val_loss: 6.1238\n",
      "Epoch 505/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3911 - val_loss: 6.7501\n",
      "Epoch 506/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4081 - val_loss: 5.4796\n",
      "Epoch 507/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3668 - val_loss: 6.8338\n",
      "Epoch 508/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3351 - val_loss: 6.7793\n",
      "Epoch 509/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0810 - val_loss: 6.0356\n",
      "Epoch 510/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9511 - val_loss: 5.9769\n",
      "Epoch 511/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.4573 - val_loss: 7.1857\n",
      "Epoch 512/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7929 - val_loss: 5.5924\n",
      "Epoch 513/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2393 - val_loss: 5.9612\n",
      "Epoch 514/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.0938 - val_loss: 5.9125\n",
      "Epoch 515/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4398 - val_loss: 5.4430\n",
      "Epoch 516/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7524 - val_loss: 5.5654\n",
      "Epoch 517/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.7724 - val_loss: 5.7355\n",
      "Epoch 518/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.0503 - val_loss: 5.7544\n",
      "Epoch 519/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1888 - val_loss: 6.0657\n",
      "Epoch 520/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1366 - val_loss: 5.2722\n",
      "Epoch 521/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 9.3554 - val_loss: 5.3818\n",
      "Epoch 522/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7188 - val_loss: 6.7998\n",
      "Epoch 523/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4506 - val_loss: 5.8673\n",
      "Epoch 524/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5955 - val_loss: 5.3097\n",
      "Epoch 525/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5591 - val_loss: 6.7838\n",
      "Epoch 526/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1717 - val_loss: 6.8907\n",
      "Epoch 527/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5548 - val_loss: 6.1131\n",
      "Epoch 528/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5071 - val_loss: 5.3540\n",
      "Epoch 529/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9614 - val_loss: 5.3651\n",
      "Epoch 530/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2987 - val_loss: 6.1333\n",
      "Epoch 531/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.6694 - val_loss: 5.5964\n",
      "Epoch 532/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2213 - val_loss: 6.2629\n",
      "Epoch 533/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.1878 - val_loss: 7.0782\n",
      "Epoch 534/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4701 - val_loss: 6.7175\n",
      "Epoch 535/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2016 - val_loss: 6.2653\n",
      "Epoch 536/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4431 - val_loss: 6.2520\n",
      "Epoch 537/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4447 - val_loss: 5.8475\n",
      "Epoch 538/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1991 - val_loss: 5.8130\n",
      "Epoch 539/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7862 - val_loss: 6.4932\n",
      "Epoch 540/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5213 - val_loss: 5.6036\n",
      "Epoch 541/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8410 - val_loss: 6.9795\n",
      "Epoch 542/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3355 - val_loss: 7.0047\n",
      "Epoch 543/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9801 - val_loss: 5.8744\n",
      "Epoch 544/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2534 - val_loss: 6.4299\n",
      "Epoch 545/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1624 - val_loss: 5.7342\n",
      "Epoch 546/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5372 - val_loss: 5.2576\n",
      "Epoch 547/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.3184 - val_loss: 6.1602\n",
      "Epoch 548/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2920 - val_loss: 5.6497\n",
      "Epoch 549/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.0487 - val_loss: 6.0233\n",
      "Epoch 550/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2975 - val_loss: 5.9234\n",
      "Epoch 551/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.2913 - val_loss: 6.2816\n",
      "Epoch 552/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7063 - val_loss: 6.3454\n",
      "Epoch 553/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1558 - val_loss: 5.9165\n",
      "Epoch 554/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6844 - val_loss: 5.1940\n",
      "Epoch 555/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.7247 - val_loss: 5.8812\n",
      "Epoch 556/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7997 - val_loss: 5.8151\n",
      "Epoch 557/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7104 - val_loss: 5.9173\n",
      "Epoch 558/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3787 - val_loss: 5.3175\n",
      "Epoch 559/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2482 - val_loss: 6.4671\n",
      "Epoch 560/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1473 - val_loss: 5.6856\n",
      "Epoch 561/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1294 - val_loss: 6.5114\n",
      "Epoch 562/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0183 - val_loss: 6.0775\n",
      "Epoch 563/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.1499 - val_loss: 6.1437\n",
      "Epoch 564/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.6581 - val_loss: 5.4706\n",
      "Epoch 565/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4093 - val_loss: 5.4015\n",
      "Epoch 566/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.6921 - val_loss: 5.2558\n",
      "Epoch 567/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4225 - val_loss: 5.4012\n",
      "Epoch 568/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.0852 - val_loss: 5.5300\n",
      "Epoch 569/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9302 - val_loss: 5.0625\n",
      "Epoch 570/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.4218 - val_loss: 6.2844\n",
      "Epoch 571/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7077 - val_loss: 5.2240\n",
      "Epoch 572/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3572 - val_loss: 5.5292\n",
      "Epoch 573/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8800 - val_loss: 5.7378\n",
      "Epoch 574/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2271 - val_loss: 5.9662\n",
      "Epoch 575/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0532 - val_loss: 6.6084\n",
      "Epoch 576/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.6406 - val_loss: 5.6584\n",
      "Epoch 577/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9381 - val_loss: 5.4071\n",
      "Epoch 578/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3252 - val_loss: 5.6206\n",
      "Epoch 579/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9322 - val_loss: 4.9352\n",
      "Epoch 580/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8182 - val_loss: 6.3537\n",
      "Epoch 581/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.9889 - val_loss: 6.0127\n",
      "Epoch 582/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.9626 - val_loss: 5.9230\n",
      "Epoch 583/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0963 - val_loss: 5.4829\n",
      "Epoch 584/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1995 - val_loss: 5.6147\n",
      "Epoch 585/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1760 - val_loss: 5.5591\n",
      "Epoch 586/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1976 - val_loss: 5.6389\n",
      "Epoch 587/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6928 - val_loss: 6.2806\n",
      "Epoch 588/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.6009 - val_loss: 5.1104\n",
      "Epoch 589/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.7950 - val_loss: 6.3951\n",
      "Epoch 590/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8177 - val_loss: 5.6345\n",
      "Epoch 591/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1047 - val_loss: 6.2557\n",
      "Epoch 592/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9928 - val_loss: 5.8902\n",
      "Epoch 593/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5731 - val_loss: 5.1320\n",
      "Epoch 594/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5521 - val_loss: 5.1887\n",
      "Epoch 595/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2304 - val_loss: 5.3821\n",
      "Epoch 596/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0252 - val_loss: 5.8370\n",
      "Epoch 597/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7421 - val_loss: 5.8064\n",
      "Epoch 598/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0671 - val_loss: 5.7167\n",
      "Epoch 599/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6126 - val_loss: 5.5955\n",
      "Epoch 600/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1473 - val_loss: 5.2643\n",
      "Epoch 601/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3907 - val_loss: 5.6620\n",
      "Epoch 602/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.5028 - val_loss: 5.6411\n",
      "Epoch 603/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8484 - val_loss: 6.2880\n",
      "Epoch 604/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5984 - val_loss: 5.0331\n",
      "Epoch 605/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.6783 - val_loss: 5.5047\n",
      "Epoch 606/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.4650 - val_loss: 5.7709\n",
      "Epoch 607/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1487 - val_loss: 6.5926\n",
      "Epoch 608/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7706 - val_loss: 5.1885\n",
      "Epoch 609/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.4619 - val_loss: 5.4891\n",
      "Epoch 610/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7101 - val_loss: 5.1797\n",
      "Epoch 611/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9253 - val_loss: 5.3834\n",
      "Epoch 612/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.2117 - val_loss: 5.0718\n",
      "Epoch 613/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7458 - val_loss: 5.3816\n",
      "Epoch 614/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0002 - val_loss: 6.2311\n",
      "Epoch 615/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5557 - val_loss: 4.8162\n",
      "Epoch 616/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4634 - val_loss: 5.4731\n",
      "Epoch 617/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.9942 - val_loss: 5.6032\n",
      "Epoch 618/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5107 - val_loss: 5.8361\n",
      "Epoch 619/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6888 - val_loss: 6.0074\n",
      "Epoch 620/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3005 - val_loss: 6.2329\n",
      "Epoch 621/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6430 - val_loss: 5.6520\n",
      "Epoch 622/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5429 - val_loss: 5.8860\n",
      "Epoch 623/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3319 - val_loss: 5.1376\n",
      "Epoch 624/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9046 - val_loss: 6.5282\n",
      "Epoch 625/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7899 - val_loss: 5.3388\n",
      "Epoch 626/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3002 - val_loss: 5.8183\n",
      "Epoch 627/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3860 - val_loss: 5.7204\n",
      "Epoch 628/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4350 - val_loss: 4.9216\n",
      "Epoch 629/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8775 - val_loss: 5.9716\n",
      "Epoch 630/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6535 - val_loss: 5.3946\n",
      "Epoch 631/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.9094 - val_loss: 5.9447\n",
      "Epoch 632/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5048 - val_loss: 6.7080\n",
      "Epoch 633/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2369 - val_loss: 5.4535\n",
      "Epoch 634/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9948 - val_loss: 5.6380\n",
      "Epoch 635/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1313 - val_loss: 5.2198\n",
      "Epoch 636/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6299 - val_loss: 5.2268\n",
      "Epoch 637/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1444 - val_loss: 6.6162\n",
      "Epoch 638/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1303 - val_loss: 6.6868\n",
      "Epoch 639/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1664 - val_loss: 5.1080\n",
      "Epoch 640/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0919 - val_loss: 5.0290\n",
      "Epoch 641/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8687 - val_loss: 5.2328\n",
      "Epoch 642/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6021 - val_loss: 4.8414\n",
      "Epoch 643/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0588 - val_loss: 6.1127\n",
      "Epoch 644/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1697 - val_loss: 4.9581\n",
      "Epoch 645/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6577 - val_loss: 6.2269\n",
      "Epoch 646/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4838 - val_loss: 5.0225\n",
      "Epoch 647/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.6479 - val_loss: 6.1927\n",
      "Epoch 648/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1779 - val_loss: 4.8491\n",
      "Epoch 649/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.7742 - val_loss: 6.1672\n",
      "Epoch 650/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1714 - val_loss: 4.6589\n",
      "Epoch 651/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.6488 - val_loss: 6.4093\n",
      "Epoch 652/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.4376 - val_loss: 5.4513\n",
      "Epoch 653/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5980 - val_loss: 5.3767\n",
      "Epoch 654/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.1906 - val_loss: 4.6141\n",
      "Epoch 655/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9489 - val_loss: 5.7759\n",
      "Epoch 656/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0632 - val_loss: 5.1472\n",
      "Epoch 657/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0723 - val_loss: 5.2195\n",
      "Epoch 658/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9056 - val_loss: 5.1918\n",
      "Epoch 659/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8194 - val_loss: 4.8661\n",
      "Epoch 660/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7755 - val_loss: 5.3990\n",
      "Epoch 661/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.1371 - val_loss: 5.3901\n",
      "Epoch 662/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7560 - val_loss: 5.3824\n",
      "Epoch 663/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1103 - val_loss: 4.7654\n",
      "Epoch 664/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3558 - val_loss: 4.7482\n",
      "Epoch 665/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6279 - val_loss: 5.5805\n",
      "Epoch 666/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3400 - val_loss: 4.7787\n",
      "Epoch 667/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8477 - val_loss: 5.4781\n",
      "Epoch 668/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0673 - val_loss: 5.1087\n",
      "Epoch 669/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5700 - val_loss: 5.0086\n",
      "Epoch 670/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2538 - val_loss: 4.8718\n",
      "Epoch 671/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0027 - val_loss: 5.3466\n",
      "Epoch 672/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5121 - val_loss: 5.6360\n",
      "Epoch 673/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1755 - val_loss: 4.4697\n",
      "Epoch 674/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5115 - val_loss: 5.6978\n",
      "Epoch 675/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8591 - val_loss: 5.8666\n",
      "Epoch 676/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2582 - val_loss: 5.3802\n",
      "Epoch 677/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0365 - val_loss: 4.7228\n",
      "Epoch 678/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7463 - val_loss: 5.3540\n",
      "Epoch 679/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1987 - val_loss: 4.4741\n",
      "Epoch 680/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2716 - val_loss: 5.2685\n",
      "Epoch 681/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.6297 - val_loss: 6.2389\n",
      "Epoch 682/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.5055 - val_loss: 5.9849\n",
      "Epoch 683/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.4646 - val_loss: 5.1700\n",
      "Epoch 684/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4234 - val_loss: 5.5928\n",
      "Epoch 685/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1977 - val_loss: 4.9113\n",
      "Epoch 686/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.9634 - val_loss: 5.3683\n",
      "Epoch 687/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.8722 - val_loss: 5.2044\n",
      "Epoch 688/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9997 - val_loss: 6.1889\n",
      "Epoch 689/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0402 - val_loss: 5.1218\n",
      "Epoch 690/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5768 - val_loss: 5.0576\n",
      "Epoch 691/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4362 - val_loss: 5.9475\n",
      "Epoch 692/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4122 - val_loss: 6.0443\n",
      "Epoch 693/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8090 - val_loss: 5.9856\n",
      "Epoch 694/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.5656 - val_loss: 5.7839\n",
      "Epoch 695/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8901 - val_loss: 5.2017\n",
      "Epoch 696/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2739 - val_loss: 5.3846\n",
      "Epoch 697/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.1428 - val_loss: 5.2517\n",
      "Epoch 698/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5299 - val_loss: 5.5789\n",
      "Epoch 699/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.9077 - val_loss: 5.3296\n",
      "Epoch 700/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6386 - val_loss: 5.4512\n",
      "Epoch 701/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2303 - val_loss: 6.1586\n",
      "Epoch 702/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 8.0492 - val_loss: 5.6416\n",
      "Epoch 703/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4372 - val_loss: 6.1522\n",
      "Epoch 704/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4155 - val_loss: 5.0392\n",
      "Epoch 705/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4824 - val_loss: 5.3861\n",
      "Epoch 706/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0193 - val_loss: 5.5782\n",
      "Epoch 707/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9860 - val_loss: 5.1472\n",
      "Epoch 708/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1781 - val_loss: 4.9778\n",
      "Epoch 709/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6076 - val_loss: 4.8742\n",
      "Epoch 710/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.0057 - val_loss: 5.5709\n",
      "Epoch 711/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0922 - val_loss: 5.3838\n",
      "Epoch 712/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4212 - val_loss: 5.1638\n",
      "Epoch 713/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6332 - val_loss: 5.5005\n",
      "Epoch 714/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.2793 - val_loss: 5.4361\n",
      "Epoch 715/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.7543 - val_loss: 4.8346\n",
      "Epoch 716/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2475 - val_loss: 4.4880\n",
      "Epoch 717/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0505 - val_loss: 4.9048\n",
      "Epoch 718/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8963 - val_loss: 5.5548\n",
      "Epoch 719/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7752 - val_loss: 5.5651\n",
      "Epoch 720/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2260 - val_loss: 5.4415\n",
      "Epoch 721/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.1826 - val_loss: 5.7536\n",
      "Epoch 722/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.3309 - val_loss: 5.1543\n",
      "Epoch 723/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.4978 - val_loss: 4.9618\n",
      "Epoch 724/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4371 - val_loss: 4.6580\n",
      "Epoch 725/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3335 - val_loss: 5.1491\n",
      "Epoch 726/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7275 - val_loss: 5.7946\n",
      "Epoch 727/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8527 - val_loss: 4.9651\n",
      "Epoch 728/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5541 - val_loss: 5.5059\n",
      "Epoch 729/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7618 - val_loss: 6.1010\n",
      "Epoch 730/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5036 - val_loss: 5.7336\n",
      "Epoch 731/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2572 - val_loss: 5.5900\n",
      "Epoch 732/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5938 - val_loss: 6.5629\n",
      "Epoch 733/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5325 - val_loss: 5.6816\n",
      "Epoch 734/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.2133 - val_loss: 5.3047\n",
      "Epoch 735/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0339 - val_loss: 4.6084\n",
      "Epoch 736/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1390 - val_loss: 5.7071\n",
      "Epoch 737/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7787 - val_loss: 5.4482\n",
      "Epoch 738/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3186 - val_loss: 5.7910\n",
      "Epoch 739/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5461 - val_loss: 4.7920\n",
      "Epoch 740/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2242 - val_loss: 5.4304\n",
      "Epoch 741/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8823 - val_loss: 5.6470\n",
      "Epoch 742/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3379 - val_loss: 4.7423\n",
      "Epoch 743/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4370 - val_loss: 5.1470\n",
      "Epoch 744/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.0490 - val_loss: 5.5340\n",
      "Epoch 745/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7310 - val_loss: 5.3112\n",
      "Epoch 746/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4282 - val_loss: 5.5209\n",
      "Epoch 747/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3020 - val_loss: 5.4877\n",
      "Epoch 748/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.8701 - val_loss: 4.8592\n",
      "Epoch 749/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9149 - val_loss: 4.8432\n",
      "Epoch 750/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8245 - val_loss: 5.9526\n",
      "Epoch 751/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9049 - val_loss: 5.4450\n",
      "Epoch 752/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7421 - val_loss: 6.3159\n",
      "Epoch 753/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.5861 - val_loss: 5.3269\n",
      "Epoch 754/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3983 - val_loss: 5.5339\n",
      "Epoch 755/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1597 - val_loss: 4.9408\n",
      "Epoch 756/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5206 - val_loss: 5.4353\n",
      "Epoch 757/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3354 - val_loss: 5.1773\n",
      "Epoch 758/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0211 - val_loss: 5.4469\n",
      "Epoch 759/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0580 - val_loss: 5.8997\n",
      "Epoch 760/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7103 - val_loss: 5.3600\n",
      "Epoch 761/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.3880 - val_loss: 5.6531\n",
      "Epoch 762/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5055 - val_loss: 4.9589\n",
      "Epoch 763/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.8352 - val_loss: 4.8026\n",
      "Epoch 764/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1988 - val_loss: 5.5439\n",
      "Epoch 765/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0645 - val_loss: 4.9007\n",
      "Epoch 766/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4491 - val_loss: 4.9409\n",
      "Epoch 767/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.6374 - val_loss: 4.9696\n",
      "Epoch 768/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5399 - val_loss: 4.8944\n",
      "Epoch 769/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8836 - val_loss: 5.2858\n",
      "Epoch 770/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0660 - val_loss: 5.0164\n",
      "Epoch 771/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.5587 - val_loss: 5.3629\n",
      "Epoch 772/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9496 - val_loss: 6.0217\n",
      "Epoch 773/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0421 - val_loss: 4.4921\n",
      "Epoch 774/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.7485 - val_loss: 5.9350\n",
      "Epoch 775/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1350 - val_loss: 5.4627\n",
      "Epoch 776/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9854 - val_loss: 4.7295\n",
      "Epoch 777/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0124 - val_loss: 5.2919\n",
      "Epoch 778/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4673 - val_loss: 5.1133\n",
      "Epoch 779/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.5593 - val_loss: 5.2100\n",
      "Epoch 780/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1461 - val_loss: 5.9166\n",
      "Epoch 781/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6510 - val_loss: 5.3302\n",
      "Epoch 782/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.9215 - val_loss: 5.6242\n",
      "Epoch 783/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8616 - val_loss: 5.2086\n",
      "Epoch 784/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9179 - val_loss: 5.7561\n",
      "Epoch 785/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.3767 - val_loss: 4.5952\n",
      "Epoch 786/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8818 - val_loss: 5.7691\n",
      "Epoch 787/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4931 - val_loss: 5.2653\n",
      "Epoch 788/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9418 - val_loss: 4.6422\n",
      "Epoch 789/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1926 - val_loss: 4.8120\n",
      "Epoch 790/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7629 - val_loss: 5.0964\n",
      "Epoch 791/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.5922 - val_loss: 6.5520\n",
      "Epoch 792/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4312 - val_loss: 5.2259\n",
      "Epoch 793/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0134 - val_loss: 4.5520\n",
      "Epoch 794/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5513 - val_loss: 5.4417\n",
      "Epoch 795/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0313 - val_loss: 5.2254\n",
      "Epoch 796/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1726 - val_loss: 4.7946\n",
      "Epoch 797/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3726 - val_loss: 5.3517\n",
      "Epoch 798/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8970 - val_loss: 5.3603\n",
      "Epoch 799/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9006 - val_loss: 5.1788\n",
      "Epoch 800/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7973 - val_loss: 5.8542\n",
      "Epoch 801/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3045 - val_loss: 5.6301\n",
      "Epoch 802/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2450 - val_loss: 5.0467\n",
      "Epoch 803/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5139 - val_loss: 5.5692\n",
      "Epoch 804/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4398 - val_loss: 5.4088\n",
      "Epoch 805/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.3761 - val_loss: 5.4300\n",
      "Epoch 806/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.2117 - val_loss: 5.7337\n",
      "Epoch 807/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1761 - val_loss: 5.0432\n",
      "Epoch 808/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0864 - val_loss: 5.4102\n",
      "Epoch 809/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.5106 - val_loss: 5.3967\n",
      "Epoch 810/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8375 - val_loss: 5.8230\n",
      "Epoch 811/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0909 - val_loss: 5.0457\n",
      "Epoch 812/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1021 - val_loss: 4.7708\n",
      "Epoch 813/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.8814 - val_loss: 5.4101\n",
      "Epoch 814/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0274 - val_loss: 4.9281\n",
      "Epoch 815/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0418 - val_loss: 4.4472\n",
      "Epoch 816/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.8919 - val_loss: 5.8420\n",
      "Epoch 817/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.1405 - val_loss: 4.9866\n",
      "Epoch 818/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0797 - val_loss: 4.5902\n",
      "Epoch 819/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9855 - val_loss: 4.9005\n",
      "Epoch 820/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4224 - val_loss: 4.5623\n",
      "Epoch 821/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2959 - val_loss: 5.1117\n",
      "Epoch 822/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4559 - val_loss: 5.6387\n",
      "Epoch 823/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3734 - val_loss: 5.0970\n",
      "Epoch 824/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1407 - val_loss: 4.7550\n",
      "Epoch 825/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7148 - val_loss: 5.3675\n",
      "Epoch 826/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0548 - val_loss: 4.8059\n",
      "Epoch 827/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1788 - val_loss: 4.9556\n",
      "Epoch 828/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1474 - val_loss: 4.9883\n",
      "Epoch 829/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8969 - val_loss: 5.5745\n",
      "Epoch 830/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6350 - val_loss: 4.2199\n",
      "Epoch 831/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2963 - val_loss: 5.2054\n",
      "Epoch 832/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6889 - val_loss: 6.0219\n",
      "Epoch 833/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.0533 - val_loss: 4.5604\n",
      "Epoch 834/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5541 - val_loss: 5.1467\n",
      "Epoch 835/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7154 - val_loss: 5.1170\n",
      "Epoch 836/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4808 - val_loss: 4.8228\n",
      "Epoch 837/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.6833 - val_loss: 5.1587\n",
      "Epoch 838/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3493 - val_loss: 5.4191\n",
      "Epoch 839/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3164 - val_loss: 5.5616\n",
      "Epoch 840/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3513 - val_loss: 5.5845\n",
      "Epoch 841/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9403 - val_loss: 4.9928\n",
      "Epoch 842/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3838 - val_loss: 5.1409\n",
      "Epoch 843/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5210 - val_loss: 5.6865\n",
      "Epoch 844/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7801 - val_loss: 4.7871\n",
      "Epoch 845/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9845 - val_loss: 5.6804\n",
      "Epoch 846/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4471 - val_loss: 5.2058\n",
      "Epoch 847/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2746 - val_loss: 5.2040\n",
      "Epoch 848/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2290 - val_loss: 4.5124\n",
      "Epoch 849/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3313 - val_loss: 4.5689\n",
      "Epoch 850/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6244 - val_loss: 5.0216\n",
      "Epoch 851/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.5527 - val_loss: 6.0074\n",
      "Epoch 852/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6242 - val_loss: 4.9407\n",
      "Epoch 853/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2822 - val_loss: 5.4042\n",
      "Epoch 854/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.6906 - val_loss: 5.7895\n",
      "Epoch 855/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.4518 - val_loss: 4.6915\n",
      "Epoch 856/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7762 - val_loss: 5.4156\n",
      "Epoch 857/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5576 - val_loss: 4.9025\n",
      "Epoch 858/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8060 - val_loss: 4.6800\n",
      "Epoch 859/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4630 - val_loss: 5.4965\n",
      "Epoch 860/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5834 - val_loss: 5.3020\n",
      "Epoch 861/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8540 - val_loss: 4.5390\n",
      "Epoch 862/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4699 - val_loss: 4.3922\n",
      "Epoch 863/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3292 - val_loss: 4.7768\n",
      "Epoch 864/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5809 - val_loss: 4.7115\n",
      "Epoch 865/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9332 - val_loss: 5.5820\n",
      "Epoch 866/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4036 - val_loss: 4.6199\n",
      "Epoch 867/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9308 - val_loss: 5.1036\n",
      "Epoch 868/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9272 - val_loss: 5.2582\n",
      "Epoch 869/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1864 - val_loss: 4.4391\n",
      "Epoch 870/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6504 - val_loss: 4.5595\n",
      "Epoch 871/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3750 - val_loss: 4.9830\n",
      "Epoch 872/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7278 - val_loss: 5.2187\n",
      "Epoch 873/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3579 - val_loss: 4.7082\n",
      "Epoch 874/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.7213 - val_loss: 5.3500\n",
      "Epoch 875/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8184 - val_loss: 5.4327\n",
      "Epoch 876/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0432 - val_loss: 5.3690\n",
      "Epoch 877/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4762 - val_loss: 5.0557\n",
      "Epoch 878/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8963 - val_loss: 5.0624\n",
      "Epoch 879/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4447 - val_loss: 5.2222\n",
      "Epoch 880/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2273 - val_loss: 4.8759\n",
      "Epoch 881/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0566 - val_loss: 5.4086\n",
      "Epoch 882/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4485 - val_loss: 4.7733\n",
      "Epoch 883/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2915 - val_loss: 6.0135\n",
      "Epoch 884/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7762 - val_loss: 4.6710\n",
      "Epoch 885/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1986 - val_loss: 5.7702\n",
      "Epoch 886/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.5550 - val_loss: 4.8430\n",
      "Epoch 887/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0013 - val_loss: 4.7790\n",
      "Epoch 888/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.2804 - val_loss: 5.1665\n",
      "Epoch 889/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8294 - val_loss: 5.5195\n",
      "Epoch 890/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8871 - val_loss: 5.2232\n",
      "Epoch 891/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9166 - val_loss: 5.0306\n",
      "Epoch 892/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.8049 - val_loss: 5.4592\n",
      "Epoch 893/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1675 - val_loss: 5.1837\n",
      "Epoch 894/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9984 - val_loss: 5.1072\n",
      "Epoch 895/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4030 - val_loss: 4.7353\n",
      "Epoch 896/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8240 - val_loss: 4.8288\n",
      "Epoch 897/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2220 - val_loss: 4.7786\n",
      "Epoch 898/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0079 - val_loss: 5.0179\n",
      "Epoch 899/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2449 - val_loss: 5.4937\n",
      "Epoch 900/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8213 - val_loss: 4.7791\n",
      "Epoch 901/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1923 - val_loss: 4.3973\n",
      "Epoch 902/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2824 - val_loss: 5.5412\n",
      "Epoch 903/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1110 - val_loss: 4.7262\n",
      "Epoch 904/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9532 - val_loss: 4.9614\n",
      "Epoch 905/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7621 - val_loss: 4.5754\n",
      "Epoch 906/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.9193 - val_loss: 5.7687\n",
      "Epoch 907/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4046 - val_loss: 5.3703\n",
      "Epoch 908/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0416 - val_loss: 4.9000\n",
      "Epoch 909/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 7.2512 - val_loss: 5.1336\n",
      "Epoch 910/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8001 - val_loss: 5.4032\n",
      "Epoch 911/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3279 - val_loss: 5.0495\n",
      "Epoch 912/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1709 - val_loss: 4.8498\n",
      "Epoch 913/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9264 - val_loss: 5.1017\n",
      "Epoch 914/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6668 - val_loss: 5.5013\n",
      "Epoch 915/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8330 - val_loss: 5.0415\n",
      "Epoch 916/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2512 - val_loss: 4.8760\n",
      "Epoch 917/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4491 - val_loss: 5.1453\n",
      "Epoch 918/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.2111 - val_loss: 5.0965\n",
      "Epoch 919/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.9473 - val_loss: 5.4036\n",
      "Epoch 920/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.4675 - val_loss: 4.2617\n",
      "Epoch 921/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8953 - val_loss: 4.8251\n",
      "Epoch 922/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3334 - val_loss: 4.1390\n",
      "Epoch 923/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8309 - val_loss: 4.6203\n",
      "Epoch 924/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.5982 - val_loss: 4.9787\n",
      "Epoch 925/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5047 - val_loss: 4.3911\n",
      "Epoch 926/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8283 - val_loss: 4.7047\n",
      "Epoch 927/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.5465 - val_loss: 4.8255\n",
      "Epoch 928/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2771 - val_loss: 4.8926\n",
      "Epoch 929/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.6604 - val_loss: 4.7105\n",
      "Epoch 930/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3336 - val_loss: 4.5874\n",
      "Epoch 931/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.7813 - val_loss: 5.3020\n",
      "Epoch 932/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4522 - val_loss: 5.0117\n",
      "Epoch 933/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0990 - val_loss: 5.2900\n",
      "Epoch 934/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8975 - val_loss: 4.7162\n",
      "Epoch 935/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5107 - val_loss: 4.5004\n",
      "Epoch 936/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1023 - val_loss: 4.6873\n",
      "Epoch 937/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2900 - val_loss: 5.5036\n",
      "Epoch 938/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6881 - val_loss: 5.0589\n",
      "Epoch 939/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8427 - val_loss: 4.1899\n",
      "Epoch 940/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6908 - val_loss: 5.0788\n",
      "Epoch 941/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0988 - val_loss: 4.9075\n",
      "Epoch 942/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0605 - val_loss: 4.4668\n",
      "Epoch 943/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8181 - val_loss: 5.0220\n",
      "Epoch 944/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8281 - val_loss: 4.4252\n",
      "Epoch 945/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7702 - val_loss: 5.7675\n",
      "Epoch 946/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.6852 - val_loss: 4.7975\n",
      "Epoch 947/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.3793 - val_loss: 4.9179\n",
      "Epoch 948/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7364 - val_loss: 5.0514\n",
      "Epoch 949/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4622 - val_loss: 5.5064\n",
      "Epoch 950/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.5216 - val_loss: 4.9875\n",
      "Epoch 951/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3999 - val_loss: 5.8401\n",
      "Epoch 952/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6894 - val_loss: 5.1653\n",
      "Epoch 953/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0498 - val_loss: 5.7646\n",
      "Epoch 954/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.1253 - val_loss: 5.1134\n",
      "Epoch 955/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8895 - val_loss: 4.9921\n",
      "Epoch 956/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.2246 - val_loss: 5.2947\n",
      "Epoch 957/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.3518 - val_loss: 4.9885\n",
      "Epoch 958/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0192 - val_loss: 4.3826\n",
      "Epoch 959/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7430 - val_loss: 5.2994\n",
      "Epoch 960/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4341 - val_loss: 4.9312\n",
      "Epoch 961/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3462 - val_loss: 4.7983\n",
      "Epoch 962/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6511 - val_loss: 5.3156\n",
      "Epoch 963/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6823 - val_loss: 4.7345\n",
      "Epoch 964/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.4595 - val_loss: 5.0720\n",
      "Epoch 965/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9155 - val_loss: 4.9214\n",
      "Epoch 966/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.7091 - val_loss: 4.8704\n",
      "Epoch 967/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8814 - val_loss: 5.4270\n",
      "Epoch 968/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8641 - val_loss: 5.5478\n",
      "Epoch 969/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.1874 - val_loss: 4.8428\n",
      "Epoch 970/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0903 - val_loss: 4.8846\n",
      "Epoch 971/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.0246 - val_loss: 5.0765\n",
      "Epoch 972/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.9967 - val_loss: 5.0699\n",
      "Epoch 973/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2471 - val_loss: 5.0123\n",
      "Epoch 974/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9866 - val_loss: 4.7873\n",
      "Epoch 975/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.5648 - val_loss: 4.5641\n",
      "Epoch 976/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7176 - val_loss: 4.6009\n",
      "Epoch 977/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6193 - val_loss: 4.9578\n",
      "Epoch 978/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7218 - val_loss: 5.1917\n",
      "Epoch 979/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.8889 - val_loss: 4.4667\n",
      "Epoch 980/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2545 - val_loss: 5.0888\n",
      "Epoch 981/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.1631 - val_loss: 4.6590\n",
      "Epoch 982/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9647 - val_loss: 4.8589\n",
      "Epoch 983/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7973 - val_loss: 4.7014\n",
      "Epoch 984/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2743 - val_loss: 4.7446\n",
      "Epoch 985/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.0723 - val_loss: 4.4343\n",
      "Epoch 986/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 6.3336 - val_loss: 4.7806\n",
      "Epoch 987/1000\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.9352 - val_loss: 4.7877\n",
      "Epoch 988/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0765 - val_loss: 4.3273\n",
      "Epoch 989/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.8415 - val_loss: 4.5971\n",
      "Epoch 990/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6392 - val_loss: 4.5725\n",
      "Epoch 991/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.5646 - val_loss: 5.1183\n",
      "Epoch 992/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9644 - val_loss: 4.9495\n",
      "Epoch 993/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.1615 - val_loss: 4.5444\n",
      "Epoch 994/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3190 - val_loss: 5.3696\n",
      "Epoch 995/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.7009 - val_loss: 5.0832\n",
      "Epoch 996/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.0347 - val_loss: 5.0048\n",
      "Epoch 997/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9808 - val_loss: 4.9115\n",
      "Epoch 998/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.3328 - val_loss: 5.1695\n",
      "Epoch 999/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2897 - val_loss: 4.9620\n",
      "Epoch 1000/1000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9256 - val_loss: 5.2129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8047fa61c0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs = 1000,initial_epoch = 100, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3db92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae233be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbebf1ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r2_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mr2_score\u001b[49m(y_test, y_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r2_score' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3aaae687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418    28.43\n",
       "474    20.44\n",
       "181    15.64\n",
       "446    24.17\n",
       "297    25.53\n",
       "       ...  \n",
       "31     21.12\n",
       "113    16.84\n",
       "272    19.11\n",
       "311    26.11\n",
       "395    21.19\n",
       "Name: ctnum_random, Length: 121, dtype: float64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c094088",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['Actual'] = y_test \n",
    "result['Predicted'] = y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c4bc6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>28.43</td>\n",
       "      <td>18.454720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>20.44</td>\n",
       "      <td>18.231291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>15.64</td>\n",
       "      <td>17.398569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>24.17</td>\n",
       "      <td>18.385277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>25.53</td>\n",
       "      <td>18.528938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.12</td>\n",
       "      <td>15.730317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>16.84</td>\n",
       "      <td>17.495449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>19.11</td>\n",
       "      <td>16.755196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>26.11</td>\n",
       "      <td>18.709843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>21.19</td>\n",
       "      <td>16.338249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "418   28.43  18.454720\n",
       "474   20.44  18.231291\n",
       "181   15.64  17.398569\n",
       "446   24.17  18.385277\n",
       "297   25.53  18.528938\n",
       "..      ...        ...\n",
       "31    21.12  15.730317\n",
       "113   16.84  17.495449\n",
       "272   19.11  16.755196\n",
       "311   26.11  18.709843\n",
       "395   21.19  16.338249\n",
       "\n",
       "[121 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a40fccb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f79f22a4c10>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "31329d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation = 'relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "0ed658f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_306 (Dense)           (None, 128)               9344      \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_310 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_312 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_315 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,945\n",
      "Trainable params: 50,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "2a870efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "8f7f2f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "6d85c71b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0942 - val_loss: 1.0236\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1394 - val_loss: 0.8680\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2090 - val_loss: 1.1568\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3457 - val_loss: 1.1106\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3833 - val_loss: 1.0983\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6208 - val_loss: 1.3471\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5218 - val_loss: 1.2307\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3500 - val_loss: 1.3441\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3743 - val_loss: 1.0671\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2273 - val_loss: 1.2246\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1552 - val_loss: 1.0415\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1898 - val_loss: 0.9557\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1114 - val_loss: 0.9566\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1703 - val_loss: 1.0437\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2735 - val_loss: 1.0186\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3353 - val_loss: 0.9106\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3476 - val_loss: 0.8643\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3225 - val_loss: 1.0215\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3342 - val_loss: 1.1651\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5227 - val_loss: 1.9248\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5251 - val_loss: 1.6128\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3007 - val_loss: 1.0664\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2334 - val_loss: 0.9235\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2821 - val_loss: 0.8446\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2689 - val_loss: 0.8745\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2081 - val_loss: 0.9975\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1230 - val_loss: 0.8571\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0985 - val_loss: 0.8090\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0652 - val_loss: 0.7518\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0611 - val_loss: 0.7754\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0623 - val_loss: 0.8252\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0501 - val_loss: 0.7755\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0476 - val_loss: 0.7467\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0380 - val_loss: 0.7882\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0699 - val_loss: 0.8464\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0643 - val_loss: 0.7818\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.7811\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0310 - val_loss: 0.7783\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0467 - val_loss: 0.7844\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0317 - val_loss: 0.7097\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.7430\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.7426\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.7101\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0206 - val_loss: 0.7326\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0364 - val_loss: 0.7377\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0390 - val_loss: 0.6927\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0303 - val_loss: 0.7478\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.6978\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.6965\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0235 - val_loss: 0.7286\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.7160\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.7312\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0246 - val_loss: 0.6951\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0384 - val_loss: 0.6986\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0291 - val_loss: 0.7347\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.7094\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.6935\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.6823\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0627 - val_loss: 0.7551\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0520 - val_loss: 0.7393\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0902 - val_loss: 0.7980\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1613 - val_loss: 0.9430\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1927 - val_loss: 0.8155\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2782 - val_loss: 1.1438\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3095 - val_loss: 0.9489\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3421 - val_loss: 0.8091\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2947 - val_loss: 0.8654\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3187 - val_loss: 0.6814\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2459 - val_loss: 0.9708\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1926 - val_loss: 0.6840\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2244 - val_loss: 0.6902\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1627 - val_loss: 0.6699\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1186 - val_loss: 0.7981\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1039 - val_loss: 0.9638\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1466 - val_loss: 0.7804\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1083 - val_loss: 0.6946\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0954 - val_loss: 0.7892\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1690 - val_loss: 0.9667\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2087 - val_loss: 1.3892\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2489 - val_loss: 0.9883\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2305 - val_loss: 0.8985\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1181 - val_loss: 0.7493\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0770 - val_loss: 0.7121\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0671 - val_loss: 0.7929\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0604 - val_loss: 0.7215\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0601 - val_loss: 0.6743\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1068 - val_loss: 0.7409\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1874 - val_loss: 0.7504\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1656 - val_loss: 0.7789\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2259 - val_loss: 1.2252\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7858 - val_loss: 2.5515\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.9673 - val_loss: 0.9726\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1092 - val_loss: 2.1268\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1003 - val_loss: 0.9848\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8708 - val_loss: 1.1143\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5553 - val_loss: 0.9571\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2619 - val_loss: 0.9434\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1825 - val_loss: 0.8171\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1178 - val_loss: 0.7652\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0791 - val_loss: 0.6589\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "e5bb97d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "d02c9c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.23032321898504"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "4fa084ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.101204831109165"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "dea8c9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.22825210676029"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "1d060f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f80747fe1c0>]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "3841a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation = 'relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "98e3db23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_317 (Dense)           (None, 128)               9344      \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_320 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,945\n",
      "Trainable params: 50,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "547d752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "21eb99af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 374.2405 - val_loss: 251.6375\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 150.4315 - val_loss: 73.0094\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 32.3961 - val_loss: 9.1281\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.4171 - val_loss: 6.2590\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.8157 - val_loss: 6.1768\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0467 - val_loss: 6.7766\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1704 - val_loss: 6.5598\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0713 - val_loss: 6.3127\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0850 - val_loss: 6.4277\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0814 - val_loss: 6.6209\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0796 - val_loss: 6.4576\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1087 - val_loss: 6.4651\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1095 - val_loss: 6.3864\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1007 - val_loss: 6.4677\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1034 - val_loss: 6.5145\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0842 - val_loss: 6.4809\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1332 - val_loss: 6.4504\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0867 - val_loss: 6.5749\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0900 - val_loss: 6.4226\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0850 - val_loss: 6.5392\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1238 - val_loss: 6.4578\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0743 - val_loss: 6.3576\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1082 - val_loss: 6.4126\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0749 - val_loss: 6.5649\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1064 - val_loss: 6.4744\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1280 - val_loss: 6.6160\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1500 - val_loss: 6.2897\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1285 - val_loss: 6.4780\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1224 - val_loss: 6.5167\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0825 - val_loss: 6.2705\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1011 - val_loss: 6.4728\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0851 - val_loss: 6.3301\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1026 - val_loss: 6.4715\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1649 - val_loss: 6.4816\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1655 - val_loss: 6.3897\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0985 - val_loss: 6.6299\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0996 - val_loss: 6.3059\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.2480 - val_loss: 6.5074\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1093 - val_loss: 6.2898\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1507 - val_loss: 6.5073\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1229 - val_loss: 6.6151\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1871 - val_loss: 6.6678\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1226 - val_loss: 6.3457\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1648 - val_loss: 6.6357\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.3353 - val_loss: 6.3240\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0932 - val_loss: 6.5957\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1137 - val_loss: 6.5488\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1239 - val_loss: 6.5955\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1503 - val_loss: 6.2739\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1111 - val_loss: 6.4829\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0922 - val_loss: 6.4382\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0951 - val_loss: 6.3736\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0868 - val_loss: 6.4969\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.1114 - val_loss: 6.5368\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1240 - val_loss: 6.3214\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0824 - val_loss: 6.4255\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0871 - val_loss: 6.3650\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0932 - val_loss: 6.4493\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1275 - val_loss: 6.5086\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1178 - val_loss: 6.6815\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.2315 - val_loss: 6.4127\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.6904 - val_loss: 6.4352\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 7.1746 - val_loss: 3.4035\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 6.3041 - val_loss: 3.6186\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.8939 - val_loss: 3.2506\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.7743 - val_loss: 3.1622\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.2442 - val_loss: 4.3141\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.2220 - val_loss: 3.3314\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.6128 - val_loss: 3.0596\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3063 - val_loss: 2.3168\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.8722 - val_loss: 1.8521\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.6797 - val_loss: 1.7494\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.4005 - val_loss: 1.3646\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8717 - val_loss: 1.2636\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.8802 - val_loss: 1.6480\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.6282 - val_loss: 1.2553\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.4149 - val_loss: 1.2607\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.1760 - val_loss: 1.1790\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.2052 - val_loss: 1.1143\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0236 - val_loss: 1.0188\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7943 - val_loss: 1.1600\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7486 - val_loss: 0.9024\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6124 - val_loss: 0.8187\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5556 - val_loss: 0.7913\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4882 - val_loss: 0.8193\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4360 - val_loss: 0.6813\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4003 - val_loss: 0.6776\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4408 - val_loss: 0.7786\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3792 - val_loss: 0.6484\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2758 - val_loss: 0.6353\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2305 - val_loss: 0.6023\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1919 - val_loss: 0.5532\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1675 - val_loss: 0.5899\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1449 - val_loss: 0.5768\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1119 - val_loss: 0.5182\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1043 - val_loss: 0.5629\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0946 - val_loss: 0.5483\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0841 - val_loss: 0.4954\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0620 - val_loss: 0.4734\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0587 - val_loss: 0.4883\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab0990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "1ca669a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 10ms/step - loss: 427.1524 - val_loss: 352.1565\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 192.2729 - val_loss: 144.3001\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 94.8421 - val_loss: 85.1043\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 68.9010 - val_loss: 64.1716\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 52.3219 - val_loss: 49.0138\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 40.2365 - val_loss: 37.5518\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 31.3065 - val_loss: 29.0505\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 24.7886 - val_loss: 22.7504\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 20.0807 - val_loss: 18.0437\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 16.7723 - val_loss: 14.5833\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 14.4103 - val_loss: 12.1938\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 12.8460 - val_loss: 10.4867\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.8167 - val_loss: 9.2443\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 11.1250 - val_loss: 8.4143\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.7033 - val_loss: 7.7836\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.4394 - val_loss: 7.3568\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.2721 - val_loss: 7.0808\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1769 - val_loss: 6.9102\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.1331 - val_loss: 6.7669\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0960 - val_loss: 6.6635\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0828 - val_loss: 6.5788\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0740 - val_loss: 6.5314\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0707 - val_loss: 6.5092\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0756 - val_loss: 6.4659\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0758 - val_loss: 6.5039\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0695 - val_loss: 6.4887\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0700 - val_loss: 6.4923\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0696 - val_loss: 6.4826\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0694 - val_loss: 6.4989\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0682 - val_loss: 6.4849\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0684 - val_loss: 6.4618\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0683 - val_loss: 6.4450\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0690 - val_loss: 6.4247\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0646 - val_loss: 6.4421\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 62.0755 - val_loss: 347.3365\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 61.1422 - val_loss: 8.4719\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.5425 - val_loss: 7.6987\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.4713 - val_loss: 7.2418\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.1714 - val_loss: 6.7674\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 10.0826 - val_loss: 6.5781\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0592 - val_loss: 6.4897\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0339 - val_loss: 6.4809\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.0149 - val_loss: 6.4866\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.9847 - val_loss: 6.4754\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.9230 - val_loss: 6.4857\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.8194 - val_loss: 6.4408\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.7026 - val_loss: 6.4186\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.5094 - val_loss: 6.2788\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 9.3102 - val_loss: 6.0875\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 8.8583 - val_loss: 5.9474\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 8.5316 - val_loss: 5.7168\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.8960 - val_loss: 5.4222\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.2958 - val_loss: 4.6869\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 6.4413 - val_loss: 3.9733\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 5.3866 - val_loss: 3.3583\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.2188 - val_loss: 3.2298\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 4.3828 - val_loss: 2.6625\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.6999 - val_loss: 2.3560\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.3971 - val_loss: 2.1740\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.2126 - val_loss: 2.1109\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.0695 - val_loss: 2.1718\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.9823 - val_loss: 1.9904\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.8898 - val_loss: 1.9666\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.8012 - val_loss: 1.9490\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.8464 - val_loss: 1.8078\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.7805 - val_loss: 2.0790\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.8015 - val_loss: 2.1167\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.8455 - val_loss: 1.7747\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.5617 - val_loss: 1.6644\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.5169 - val_loss: 1.6671\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.4276 - val_loss: 1.5496\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.3785 - val_loss: 1.4915\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.3165 - val_loss: 1.6133\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.3707 - val_loss: 1.4805\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.1897 - val_loss: 1.3781\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.2154 - val_loss: 1.3592\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2059 - val_loss: 1.3826\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.0537 - val_loss: 1.2279\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.9873 - val_loss: 1.2405\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 2.0130 - val_loss: 1.1944\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.8189 - val_loss: 1.2829\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 1.7850 - val_loss: 1.1203\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.7023 - val_loss: 1.0938\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.6269 - val_loss: 1.1184\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.7075 - val_loss: 1.0992\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.4749 - val_loss: 1.1391\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.4424 - val_loss: 1.1008\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.4129 - val_loss: 1.1230\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3785 - val_loss: 1.1112\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.4394 - val_loss: 1.0500\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3826 - val_loss: 1.1477\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.3441 - val_loss: 1.0373\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2722 - val_loss: 1.0616\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.2388 - val_loss: 1.0574\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.2389 - val_loss: 1.0455\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1549 - val_loss: 1.1199\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1380 - val_loss: 1.2425\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.2194 - val_loss: 1.2715\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0967 - val_loss: 1.1435\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0413 - val_loss: 1.0677\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "51.666070292958665\n",
      "1.8576466862323855\n",
      "5.845268839464395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f80578e6a30>]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation = 'tanh', input_dim = X_train.shape[1]))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(64, activation = 'tanh'))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "history = model.fit(X_train, y_train, epochs = 100, validation_split = 0.2)\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "b26579c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_score = r2_score(y_test, y_pred)*100\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse  = mean_squared_error(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "1fbe0fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.666070292958665"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "8adf7b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8576466862323855"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "2f232c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f80565077f0>]"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "d795c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['Mean Absolute Error'] = [mae,'NAN']\n",
    "result['Mean Squared Error'] = [mse,'NAN']\n",
    "result['R2 Score'] = [R2_score,'NAN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "91a4accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"regdlresult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "d31a3810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in ./anaconda3/lib/python3.9/site-packages (3.6.0)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in ./anaconda3/lib/python3.9/site-packages (from h5py) (1.21.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "0374525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# equivalent to: model.save(\"model.h5\")\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "#save_model(model, \"reg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "8f3d57ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('reg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02790744",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.h5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
